---
title: "Trabalho de Extra√ß√£o"
subtitle: "Brain Lower Glioma"
author: "C√°tia Ros√°rio (pg57791) + Vanessa Rodriguez (pg49131) + Andr√© Dias (pg55127)"
date: "2025-03-21"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: yes
---

```{=html}
<style>
body {
text-align: justify}
</style>
```

**Workflow:**

1.  Explica√ß√£o de origem e relev√¢ncia dos dados

2.  Prepara√ß√£o e pr√©-processamento dos dados

3.  Sumariza√ß√£o dos dados e gr√°ficos

4.  An√°lise estat√≠stica univariada

5.  An√°lise de express√£o diferencial e enriquecimento

\

## **1. Explica√ß√£o de origem e relev√¢ncia dos dados**

### Origem dos dados  
Os dados prov√™m do estudo *"LGG TCGA PanCancer Atlas 2018"*, dispon√≠vel no portal cBioPortal: [üîó cBioPortal](https://www.cbioportal.org/study/summary?id=lgg_tcga_pan_can_atlas_2018).  

Esse estudo faz parte do The Cancer Genome Atlas (TCGA), um grande projeto colaborativo que visa caracterizar geneticamente diversos tipos de cancro usando tecnologias de alto rendimento, como RNA-Seq para express√£o gen√©tica.  

---

### Tipo de cancro estudado  
Este dataset est√° focado no *Glioma de baixo grau* (Low Grade Glioma - LGG), um tipo de tumor cerebral com evolu√ß√£o mais lenta do que o glioblastoma, mas que pode ser fatal em v√°rios casos. 

Apesar da sua progress√£o mais lenta, o *LGG apresenta uma elevada heterogeneidade molecular*, tornando-se relevante para estudos de estratifica√ß√£o de pacientes e identifica√ß√£o de subtipos tumorais.  

---

### Dados dispon√≠veis  
No *cBioPortal*, este estudo inclui:  
- *Dados cl√≠nicos* (idade, sexo, sobrevida, etc.)  
- *Dados de Express√£o G√©nica* (RNA-Seq)  
- *Dados de Muta√ß√£o Som√°tica*  
- *Dados de CNV* (altera√ß√µes no n√∫mero de c√≥pias)  
- *Dados de Metila√ß√£o*  
- *Dados de Fus√µes*  

Todos esses dados s√£o *integr√°veis, permitindo an√°lises multi-√≥micas para uma vis√£o mais ampla dos mecanismos moleculares envolvidos no desenvolvimento e progress√£o do **glioma*.  
  

---

### Dados de Express√£o G√©nica (*RNA-Seq*)  
Os dados de express√£o g√©nica foram processados usando o m√©todo *RSEM, com **normaliza√ß√£o por lote* (batch-normalized) a partir da plataforma *Illumina HiSeq RNASeqV2*.  

A matriz de express√£o cont√©m *milhares de genes* (geralmente cerca de 20.000), permitindo an√°lises em larga escala de:  
- *Express√£o diferencial*  
- *Coexpress√£o*  
- *Redes regulat√≥rias*  
 

---

### Relev√¢ncia cient√≠fica  
Este tipo de dados permite identificar *genes diferencialmente expressos* entre:  
- *Subtipos tumorais*  
- *Grupos com ou sem muta√ß√µes espec√≠ficas*  
- *Amostras normais e tumorais*  

No caso do estudo, est√£o dispon√≠veis apenas as *514 amostras tumorais* de *glioma de baixo grau (LGG)*.  

Essas an√°lises podem contribuir para:  
- *Descoberta de biomarcadores moleculares*  
- *Estratifica√ß√£o de pacientes com base em perfis de express√£o*  
- *Identifica√ß√£o de poss√≠veis alvos terap√™uticos*  

Al√©m disso, os dados podem ser utilizados em *an√°lises de enriquecimento funcional* (como GSEA ou over-representation analysis) para responder a perguntas como:  

> Quais as vias biol√≥gicas que est√£o mais ativas ou reprimidas em determinados grupos de pacientes?  

Tamb√©m √© poss√≠vel *associar perfis de express√£o a desfechos cl√≠nicos, como *tempo de sobrevida ou resposta ao tratamento, contribuindo para avan√ßos na *medicina personalizada*.  

O dataset √© *compat√≠vel com t√©cnicas de machine learning*, permitindo:  
- *Classifica√ß√£o de pacientes*  
- *Sele√ß√£o de features relevantes*  
- *Predi√ß√£o de progn√≥stico*  

O *acesso aberto* e a *documenta√ß√£o clara* dispon√≠veis pelo cBioPortal *refor√ßam a reprodutibilidade cient√≠fica* e *a integra√ß√£o com ferramentas computacionais, como **APIs e bibliotecas em R ou Python*.

\

## **2. Prepara√ß√£o e pr√©-processamento dos dados**

**Workflow Dados Cl√≠nicos:**

-   Visualiza√ß√£o da estrutura dos dados

-   Remo√ß√£o de NAs

-   Manipula√ß√£o de dados

-   Sumariza√ß√£o e visualiza√ß√£o de dados

\

**Workflow Dados Express√£o G√©nica:**

-   Visualiza√ß√£o estrutura dos dados

-   Remo√ß√£o de duplicados

-   Tratamento de dados

-   Remo√ß√£o de genes pouco expressos

-   Filtragem por n√≠veis de express√£o

-   Sumariza√ß√£o e visualiza√ß√£o de dados

    \

### 2.0. Importa√ß√£o das packages e dos dados

```{r, message=F}
cran_packages <- c(
  "ggplot2",      # Visualization
  "gplots",       # Enhanced plots
  "gridExtra",    # Combine multiple plots
  "DT",           # Interactive datatables
  "dplyr",        # Data manipulation
  "plyr",         # Data manipulation (older)
  "stringr",      # String operations
  "knitr",        # RMarkdown rendering
  "data.table",   # Efficient data handling
  "viridis",      # Color palettes
  "openxlsx",     # Excel export
  "corrplot",     # Correlation plots
  "mgcv",         # GAM models
  "ggpubr",       # Publication-ready plots
  "GGally",       # Pair plots (extension of ggplot2)
  "htmltools",    # Plots
  "caret",        # Modelation
  "randomForest", # Random Forest
  "smotefamily",  # SMOTE
  "xgboost",      # xgboost
  "e1071",        # SVM
  "pROC",         # ROC CURVE
  "MLmetrics",    # F1_score
  "pander",       # Tables
  "tibble",       # Interactive datatables
  "Rtsne",        # UMAP
  "uwot",         # T-SNE
  "factoextra"    # T-SNE
  
)

bioc_packages <- c(
  "edgeR",             # RNA-seq analysis
  "limma",             # Linear models for microarray/RNA-seq
  "clusterProfiler",   # Functional enrichment
  "org.Hs.eg.db",      # Human gene annotation
  "AnnotationDbi",     # Annotation infrastructure
  "biomaRt",           # Interface to BioMart databases
  "enrichplot"         # Visualization of enrichment results
)

other_packages <- c(
  "gprofiler2"         # g:Profiler interface (CRAN but bio-focused)
)


# Installation Block

# Install BiocManager if missing
if (!requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}

# Install missing CRAN packages
cran_missing <- cran_packages[!cran_packages %in% rownames(installed.packages())]
if (length(cran_missing) > 0) install.packages(cran_missing)

# Install missing Bioconductor packages
bioc_missing <- bioc_packages[!bioc_packages %in% rownames(installed.packages())]
if (length(bioc_missing) > 0) BiocManager::install(bioc_missing)

# Install other packages (gprofiler2 is from CRAN)
other_missing <- other_packages[!other_packages %in% rownames(installed.packages())]
if (length(other_missing) > 0) install.packages(other_missing)


# Load All Packages

all_packages <- c(cran_packages, bioc_packages, other_packages)
invisible(lapply(all_packages, function(pkg) {
  suppressMessages(library(pkg, character.only = TRUE))
}))

# Import data
clini_data <- read.delim("lgg_tcga_pan_can_atlas_2018_clinical_data.tsv", stringsAsFactors=TRUE)
gene_data <- read.delim("all_genes_mrna.txt")
```


Inicialmente, foram importados os dados de express√£o g√©nica, `gene_data`, e os dados cl√≠nicos dos pacientes analisados, `clini_data`.

```{r, echo=F}
palette_3 <- c("#fd7f6f", "#7eb0d5", "#b2e061", "#bd7ebe", "#ffb55a", "#ffee65", "#beb9db", "#fdcce5", "#8bd3c7")
```

\

### 2.1. Dados Cl√≠nicos

### 2.1.1. Estrutura dos dados

A estrutura dos dados cl√≠nicos √© apresentada em baixo. Os pacientes s√£o identificados por um ID (`Patient.ID`) que faz correspond√™ncia com os dados de express√£o g√©nica. Nesta fase est√£o presentes 63 vari√°veis e 514 observa√ß√µes (listado abaixo).

```{r echo=T, message=FALSE, warning=FALSE}
# Preview dos dados
datatable(head(clini_data), options = list(scrollX = TRUE))
```

\

```{r}
# Estrutura e formato dos dados
str(clini_data)
```

\

### 2.1.2. Manipula√ß√£o de dados

A manipula√ß√£o dos dados cl√≠nicos consistiu nos seguintes processos:

1.  Convers√£o do \`Patient.ID\` para o mesmo formato do dataset `gene_data;`
2.  Remo√ß√£o de vari√°veis cl√≠nicas consideradas menos relevantes no √¢mbito do estudo - este processo foi validado com literatura associada aos dados;
3.  Simplifica√ß√£o dos nomes das colunas;
4.  Convers√£o vari√°vel de meses de sobreviv√™ncia para anos de sobreviv√™ncia - `surv_years`;

\

```{r}
# Change column names
nomes <- names(clini_data)
nomes <- gsub("[\\.]", " ", nomes)
nomes <- gsub("  ", " ", nomes)
nomes <- gsub(" $", "", nomes, perl=T)
names(clini_data) <- nomes

# Filter by columns of interest
novas_colunas<-c("Sample ID","Diagnosis Age","Cancer Type Detailed","Months of disease specific survival","Disease specific Survival status","Fraction Genome Altered","Genetic Ancestry Label","Sex","Tumor Break Load")
clini_data <- clini_data[,novas_colunas]

# Change variable names
colnames(clini_data) <- c("sample_ID","diagnosis_age","cancer_type","surv_months","surv_status","genome_alt","ancestry","sex","tbl")

```

\

```{r}
# Convert sample ID to same format as expression data
sample_id <- clini_data$sample_ID
sample_id <- gsub("-", "\\.", sample_id)
clini_data$sample_ID <- sample_id

# Convert survival months to years
clini_data$surv_months <- clini_data$surv_months/12
colnames(clini_data) <- c("sample_ID","diagnosis_age","cancer_type","surv_years","surv_status","genome_alt","ancestry","sex","tbl")
```

\

### 2.1.3. Limpeza de Dados - Remo√ß√£o de NAs

Uma vez que a propor√ß√£o de NAs √© baixa (6%), opt√°mos por remover as linhas com NAs (Listwise Deletion). Por consequente, a amostra ficou reduzida a 481 pacientes.

```{r}
# Remo√ß√£o de NAs
clini_data_no_na <- na.omit(clini_data)

# Propor√ß√£o de NAs no dataset
(nrow(clini_data) - nrow(clini_data_no_na))/nrow(clini_data)
```

\

### 2.1.4. Sumariza√ß√£o e Visualiza√ß√£o de Dados

```{r}
#  medidas de localiza√ß√£o e dispers√£o
summary(clini_data_no_na)
```

O resumo estat√≠stico dos dados permite conferir que n√£o existem anomalias nos dados (e.g. propor√ß√µes acima de 100% ou n√∫mero de anos negativos). Seguem abaixo observa√ß√µes sobre as vari√°veis:

-   **Diagnosis age** - vasta distribui√ß√£o, variando entre 14 e 87 anos;

-   **Cancer type** - Oligoastrocytoma representa 25% dos dados, sendo que os restantes s√£o mais frequentes - Oligodendroglioma (36%) e Astrocytoma (38%);

-   **Survival years** - 75% dos dados variam entre 0 e 3.4 anos, com um m√°ximo de 17.6 anos, indicando que a vari√°vel poder√° conter outliers

-   **Survival status** - 70% da amostra apresenta-se em remiss√£o (vivo ou n√£o);

-   **Genome altered** - a fra√ß√£o de genoma alterado apresenta uma grande varia√ß√£o, entre 0% e 95% de altera√ß√£o. No entanto, sendo que 75% dos dados n√£o ultrapassam 15% de altera√ß√£o, valores muito elevados poder√£o ser outliers;

-   **Ancestry** - a maioria da amostra (91%) tem ancestralidade europeia;

-   **Sex** - a amostra encontra-se sensivelmente equilibrada, com 44% de mulheres e 56% de homens;

-   **Tumor Break Load (TBL)** - esta m√©trica avalia a instabilidade gen√≥mica; 75% dos dados variam entre 0 e 37, enquanto que o valor m√°ximo √© de 618. √Ä semelhan√ßa de outras vari√°veis, esta tamb√©m aparenta ter outliers.

    \

**Numerical variables:**

-   Diagnosis Age (`diagnosis_age`)

-   Years of survival (`surv_years`)

-   Fraction Genome Altered (`genome_alt`)

-   Tumor Break Load (`tbl`)

**Factor variables:**

-   Sample ID (`sample_ID`)

-   Sex (`sex`)

-   Cancer Type (`cancer_type`)

-   Genetic Ancestry (`ancestry`)

-   Survival Status (`surv_status`)

    \

#### **Visualiza√ß√£o univariada**

```{r, fig.width = 12, message=F}
# Vari√°veis num√©ricas
a <- ggplot(alpha=0.8) + geom_histogram(data=clini_data_no_na, aes(x=diagnosis_age), fill="#7eb0d5") + theme_bw()
b <- ggplot(alpha=0.8) + geom_histogram(data=clini_data_no_na, aes(x=surv_years), fill="#7eb0d5") + theme_bw()
ggarrange(a, b)
```

A vari√°vel Diagnosis Age tem uma distribui√ß√£o pr√≥xima da distribui√ß√£o normal, enquanto que a Survival Years tem uma distribui√ß√£o enviesada √† direita.

```{r, fig.width = 12, message=F}
# Vari√°veis num√©ricas
a <- ggplot(alpha=0.8) + geom_histogram(data=clini_data_no_na, aes(x=genome_alt), fill="#7eb0d5") + theme_bw()
b <- ggplot(alpha=0.8) + geom_histogram(data=clini_data_no_na, aes(x=tbl), fill="#7eb0d5") + theme_bw()
grid.arrange(a, b, ncol=2)
```

Ambas as vari√°veis apresentam uma distribui√ß√£o enviesada √† direita.

```{r, fig.width = 12, message=F}
# Vari√°veis categ√≥ricas
a <- ggplot(alpha=0.8) + geom_bar(data=clini_data_no_na, aes(x=sex, fill=sex)) + scale_fill_manual(values = palette_3) + theme_bw()
b <- ggplot(alpha=0.8) + geom_bar(data=clini_data_no_na, aes(x=cancer_type, fill=cancer_type)) + scale_fill_manual(values = palette_3) + theme_bw()
grid.arrange(a, b, ncol=2)
```

A vari√°vel categ√≥riga Sex est√° distribuida de forma equilibrada nos dois g√©neros. A vari√°vel Cancer Type apresenta uma pequena varia√ß√£o entre os 3 tipos de cancro como referido anteriormente.

```{r, fig.width = 12, message=F}
# Vari√°veis categ√≥ricas
a <- ggplot(alpha=0.8) + geom_bar(data=clini_data_no_na, aes(x=ancestry, fill=ancestry)) + scale_fill_manual(values = palette_3) + theme_bw()
b <- ggplot(alpha=0.8) + geom_bar(data=clini_data_no_na, aes(x=surv_status, fill=surv_status)) + scale_fill_manual(values = palette_3) + theme_bw()
grid.arrange(a, b, ncol=2)
```

A an√°lise da vari√°vel Ancestry confirma o que foi dito anteriormente, apresentando a ancestralidade europeia como a amostra predominante. A vari√°vel Survival Status demonstra uma taxa elevada de pacientes em remiss√£o (vivos ou n√£o) em compara√ß√£o com os que morreram com tumor.

\

#### **Visualiza√ß√£o multivariada**

#### Vari√°vel num√©rica vs. num√©rica

```{r, fig.width = 12,fig.height = 9, message=F}
ggpairs(select_if(clini_data_no_na, is.numeric), lower = list(continuous = "smooth"))
```

Os pares Diagnosis Age - Survival Years e Diagnosis Age - Genome Alteration t√™m uma correla√ß√£o baixa, negativa e positiva, respetivamente.\
Os pares Diagnosis Age - Tumor Break Load, Survival Years - Genome Alteration and Survival Years - Tumor Break Load apresentam uma linha praticamente horizontal, pelo que n√£o aparentam ter correla√ß√£o.\
O par Genome Alteration - Tumor Break Load apresenta correla√ß√£o na ordem dos 0.484, que se mant√©m abaixo do coeficiente de correla√ß√£o de 0.5, pelo que n√£o aparenta haver multicolinearidade.

\

#### Vari√°vel num√©rica vs. categ√≥rica

```{r}
# Remover outliers
  # get outliers
out_age <- which(clini_data_no_na$diagnosis_age>(quantile(clini_data_no_na$diagnosis_age, .75) + 1.5*IQR(clini_data_no_na$diagnosis_age)))
out_surv <- which(clini_data_no_na$surv_years>(quantile(clini_data_no_na$surv_years, .75) + 1.5*IQR(clini_data_no_na$surv_years)))
out_gen <- which(clini_data_no_na$genome_alt>(quantile(clini_data_no_na$genome_alt, .75) + 1.5*IQR(clini_data_no_na$genome_alt)))
out_tbl <- which(clini_data_no_na$tbl>(quantile(clini_data_no_na$tbl, .75) + 1.5*IQR(clini_data_no_na$tbl)))

# remove outliers
no_out_data <- clini_data_no_na[-c(out_age, out_surv, out_gen, out_tbl),]

```

Ap√≥s uma an√°lise grafica inicial constatou-se que algumas vari√°veis tinham outliers, pelo que se realizou a remo√ß√£o dos mesmos.

\

##### *Vari√°vel sex*

```{r, fig.width = 12, message=F}
#### sex vs. diagnosis age
a <- ggplot(alpha=0.8, data=no_out_data, aes(x=sex, y=diagnosis_age, fill=sex)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

#### sex vs. genome altered
b <- ggplot(alpha=0.8, data=no_out_data, aes(x=sex, y=genome_alt, fill=sex))+ geom_violin()  + geom_boxplot(width=.1)  + scale_fill_manual(values = palette_3) + theme_bw()

ggarrange(a, b, common.legend=T)

```

A distribui√ß√£o das vari√°veis Diagnosis Ages e Genome Alteration em fun√ß√£o da vari√°vel Sex, representadas acima, n√£o apresentam grande varia√ß√£o entre sexos. Infere-se que n√£o h√° uma associa√ß√£o entre o sexo e essas vari√°veis.\

```{r, fig.width = 12, message=F}
#### sex vs. tbl
a <- ggplot(alpha=0.8, data=no_out_data, aes(x=sex, y=tbl, fill=sex)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

#### sex vs. survival
b <- ggplot(alpha=0.8, data=no_out_data, aes(x=sex, y=surv_years, fill=sex)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

ggarrange(a, b, common.legend=T)
```

A distribui√ß√£o das vari√°veis Tumor Break Load e Survival Years em fun√ß√£o da vari√°vel Sex, representadas acima, n√£o apresentam grande varia√ß√£o entre sexos. Infere-se que n√£o h√° uma associa√ß√£o entre o sexo e essas vari√°veis.

\

##### *Vari√°vel Cancer Type*

```{r}
#### cancer type vs. diagnosis age
ggplot(alpha=0.8, data=no_out_data, aes(x=cancer_type, y=diagnosis_age, fill=sex)) + geom_violin() + geom_boxplot(width=.1,position = position_dodge(width =0.9)) +  scale_fill_manual(values = palette_3) + theme_bw()
```

Neste gr√°fico, o cancro Oligodendroglioma apresenta uma distribui√ß√£o com mediana dos valores de Diagnosis Age acima dos outros tipos de cancro.

\

```{r, fig.width = 12, message=F}
#### cancer type vs. genome altered
ggplot(alpha=0.8, data=no_out_data, aes(x=cancer_type, y=genome_alt, fill=sex)) + geom_violin() + geom_boxplot(width=.1,position = position_dodge(width =0.9)) +  scale_fill_manual(values = palette_3) + theme_bw()

#ggarrange(a, b, common.legend=T)
```

Neste gr√°fico, foi feita uma distin√ß√£o entre sexos, devido √† ligeira diferen√ßa observada no gr√°fico individual de Genome Altered. Observa-se pouca varia√ß√£o entre os 3 tipos de cancro em rela√ß√£o √† altera√ß√£o de genoma. Entre sexos dentro dos pares h√° uma varia√ß√£o mais not√°vel nos pacientes com oligoastrocytoma.\
\

```{r, fig.width = 12, message=F}

#### cancer type vs. tbl
a <- ggplot(alpha=0.8, data=no_out_data, aes(x=cancer_type, y=tbl, fill=cancer_type)) + geom_violin() + geom_boxplot(width=.1,position = position_dodge(width =0.9)) +  scale_fill_manual(values = palette_3) + theme_bw()

#### cancer type vs. years survival
b <- ggplot(alpha=0.8, data=no_out_data, aes(x=cancer_type, y=surv_years, fill=cancer_type)) + geom_violin() + geom_boxplot(width=.2,position = position_dodge(width =0.9)) +  scale_fill_manual(values = palette_3) + theme_bw()
c <- ggplot(alpha=0.8, data=no_out_data, aes(x=cancer_type, y=surv_years, fill=cancer_type)) + geom_violin() + geom_boxplot(width=.2,position = position_dodge(width =0.9)) +  scale_fill_manual(values = palette_3) + theme_bw()

ggarrange(a, b, common.legend=T)

```

No primeiro gr√°fico verifica-se uma grande varia√ß√£o dos valores de Tumor Break Load entre tipos de cancro.\
No segundo gr√°fico n√£o se observa grande varia√ß√£o entre tipos de cancro relativamente aos valores de Survival Years.

\

##### *Vari√°vel Ancestry*

```{r, fig.width = 12, message=F}
#### ancestry vs. genome altered
a <- ggplot(no_out_data, aes(x = ancestry, y = genome_alt)) +
  geom_boxplot(fill = palette_3[1:length(unique(no_out_data$ancestry))], alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.8, color = "grey10")   +
  xlab("") + 
  theme_bw()

#### ancestry vs. age
b <- ggplot(no_out_data, aes(x = ancestry, y = diagnosis_age)) +
  geom_boxplot(fill = palette_3[1:length(unique(no_out_data$ancestry))], alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.8, color = "grey10") +
  xlab("") +
  theme_bw()

ggarrange(a, b, common.legend=T)
```

Em ambos os gr√°ficos mostram diferen√ßas significativas entre essas vari√°veis e essa varia√ß√£o pode ser devido a dimens√µes de amostra distintas.Embora dentro dos grupos com maiores dimens√µes (AFR e EUR) n√£o h√° diferen√ßas muito not√°veis.

```{r, fig.width = 12, message=F}
#### ancestry vs. tbl
a <- ggplot(no_out_data, aes(x = ancestry, y = tbl)) +
  geom_boxplot(fill = palette_3[1:length(unique(no_out_data$ancestry))], alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.8, color = "grey10")  + 
  xlab("") +
  theme_bw()

#### ancestry vs. survival
b <- ggplot(no_out_data, aes(x = ancestry, y = surv_years)) +
  geom_boxplot(fill = palette_3[1:length(unique(no_out_data$ancestry))], alpha = 0.5) + 
  geom_jitter(width = 0.2, alpha = 0.8, color = "grey10")  + 
  xlab("") +
  theme_bw()

ggarrange(a, b, common.legend=T)
```

Como observado no caso acima, ambos os gr√°ficos mostram diferen√ßas significativas entre essas vari√°veis e essa varia√ß√£o pode ser devido a dimens√µes de amostra distintas.Embora dentro dos grupos com maiores dimens√µes (AFR e EUR) n√£o h√° diferen√ßas muito not√°veis.

\

##### *Vari√°vel surv_status*

```{r, fig.width = 12, message=F}
#### sex vs. diagnosis age
a <- ggplot(alpha=0.8, data=no_out_data, aes(x=surv_status, y=diagnosis_age, fill=surv_status)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

#### sex vs. genome altered
b <- ggplot(alpha=0.8, data=no_out_data, aes(x=surv_status, y=genome_alt, fill=surv_status))+ geom_violin()  + geom_boxplot(width=.1)  + scale_fill_manual(values = palette_3) + theme_bw()

ggarrange(a, b, common.legend=T)
```

No primeiro plot observa-se uma clara distin√ß√£o entre os fatores de Survival Status com base na Diagnosis Age. Diagnosis Age tem uma mediana mais alta para Dead With Tumor. O mesmo se verifica entre a vari√°vel Genome Alteration e Survival Status.

```{r, fig.width = 12, message=F}
#### sex vs. tbl
a <- ggplot(alpha=0.8, data=no_out_data, aes(x=surv_status, y=tbl, fill=surv_status)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

#### sex vs. survival
b <- ggplot(alpha=0.8, data=no_out_data, aes(x=surv_status, y=surv_years, fill=surv_status)) + geom_violin() + geom_boxplot(width=.1) + scale_fill_manual(values = palette_3) + theme_bw()

ggarrange(a, b, common.legend=T)
```

No primeiro plot observa-se uma clara distin√ß√£o entre os fatores de Survival Status com base no Tumor Break Load. TBL tem uma mediana mais alta para Dead With Tumor. Verifica-se uma varia√ß√£o menos not√°vel entre a vari√°vel Survival Years e Survival Status.

\

### 2.2. Dados de Express√£o G√©nica

### 2.2.1. Estrutura dos dados

A estrutura dos dados de express√£o g√©nica √© apresentada em baixo. Os pacientes s√£o identificados por um ID (Patient.ID) que faz correspond√™ncia com os dados cl√≠nicos. Nesta fase est√£o presentes 10 vari√°veis e 20531 observa√ß√µes (listado abaixo).

```{r, fig.width = 12, message=F}
# Preview dos dados
head(gene_data[,1:5])
```

```{r}
# Estrutura dos dados
str(gene_data[,1:10])
```

\

### 2.2.2. Remo√ß√£o de duplicados e NAs

Nesta fase, procedeu-se a retirar genes duplicados, genes descontinuados e NAs do dataset. Em seguida, transp√¥s-se o dataset para colocar os Ids dos genes nas linhas, algo essencial para utilizar o package (EdgeR) nos passos seguintes. De modo a simplificar e ser poss√≠vel comparar dados cl√≠nicos com dados de express√£o g√©nica excluiram-se os pacientes sem dados cl√≠nicos.

```{r}
# Gene descontinuado DGCR9, row n¬∫ 4886 - ser√° removido
gene_data_nd <- gene_data[-c(4886),]

# Remove duplicates
gene_data_nd <- gene_data_nd[-c(which(duplicated(gene_data_nd$Entrez_Gene_Id))),]

# Remo√ß√£o de NAs
gene_data_nona <- na.omit(gene_data_nd)

# Propor√ß√£o de NAs no dataset
(nrow(gene_data_nd) - nrow(gene_data_nona))/nrow(gene_data_nd)

# Converter Gene ID em rownames
rownames(gene_data_nona) <- gene_data_nona$Entrez_Gene_Id

# Exclus√£o de pacientes sem dados cl√≠nicos
complete_ids <- clini_data_no_na$sample_ID
gene_data_nona <- gene_data_nona[,complete_ids]
```

\

### 2.2.3. Tratamento de dados

Para ser poss√≠vel filtrar os dados usou-se DGEList e agrupou-se os dados em 4 grupos - f_cancer, f_survival, f_ancestry and f-sex.

```{r}
# Converter em formato DGEList (package edgeR)
## sem agrupamento
d0 <- DGEList(gene_data_nona) # no grouping

# cria√ß√£o de grupos
f_cancer <- revalue(clini_data_no_na$cancer_type, c("Astrocytoma" = "A", "Oligoastrocytoma" = "B", "Oligodendroglioma" = "C", "Low-Grade Glioma (NOS)" = "D"))
f_survival <- revalue(clini_data_no_na$surv_status, c("0:ALIVE OR DEAD TUMOR FREE" = "A", "1:DEAD WITH TUMOR" = "B"))
f_ancestry <- revalue(clini_data_no_na$ancestry, c("EUR" = "A", "AFR" = "B", "AFR_ADMIX" = "C", "EAS" = "D", "EUR_ADMIX" = "E", "AMR" = "F", "SAS" = "G", "SAS_ADMIX" = "H"))
f_sex <- revalue(clini_data_no_na$sex, c("Male" = "A", "Female" = "B"))

# agrupamento por fatores
# d0_g <- DGEList(gene_data_nona, group=f_cancer) # or f_sex, etc.

# Visualizar estrutura dos dados
head(d0$samples)

```

\

### 2.2.4. Remo√ß√£o de genes pouco expressos

A primeira fase de filtragem passou por excluir os genes pouco expressos, reduzindo a lista de 20504 elementos para 14357.

```{r}
# Excluir genes pouco expressos
keep <- filterByExpr(d0) 
d0_f <- d0[keep, , keep.lib.sizes=FALSE] # pass√°mos de uma lista de 20504 elementos para 14357
```

\

### 2.2.5. Filtragem por n√≠veis de express√£o

Numa segunda fase de filtragem, utilizaram-se filtros flat patterns nomeadamente aplicar 2\*mediana (Filtro 1) e max/min \> 2 (Filtro 2), separadamente.

```{r}
# Filtros flat patterns - 2*mediana

gene_exp_sd <- apply(gene_data_nona, 1, sd)
d_med <- 2*median(gene_exp_sd)
high_exp <- which(gene_exp_sd > d_med)

mean_exp <- data.frame(gene_id=high_exp,exp=apply(gene_data_nona[high_exp,], 1, mean), row.names = c())
mean_exp$exp_max <- mean_exp$exp/max(mean_exp$exp)
mean_exp$exp_log <- log(mean_exp$exp)
```

```{r}
# Filtros flat patterns - max/min > 2
gene_min <- apply(gene_data_nona, 1, min)
gene_max <- apply(gene_data_nona, 1, max)

rat <- which(gene_max/gene_min > 2)
mean_exp_f2 <- data.frame(id=rat, exp=apply(gene_data_nona[rat,-1], 1, mean))
mean_exp_f2$exp_max <- mean_exp_f2$exp/max(mean_exp_f2$exp)
mean_exp_f2$exp_log <- log(mean_exp_f2$exp)
```

\

### 2.2.6. Sumariza√ß√£o e visualiza√ß√£o de dados

\

#### Filtro flat pattern 1

Recorrendo aos dados filtrados com o filtro 1, realizaram-se histogramas para visualizar a distribui√ß√£o dos dados (Gr√°fico da esquerda). No gr√°fico da direita, apenas se fez uma normaliza√ß√£o dos dados com log transformation de modo a poder visualizar melhor a distribui√ß√£o, que aparenta ser pr√≥xima do normal.

```{r, fig.width = 12, message=F}
# Filtro flat pattern 1
a <- ggplot(mean_exp) + geom_histogram(aes(x=exp), bins=400, fill="#7eb0d5") +ggtitle("Flat pattern 1")
b <- ggplot(mean_exp) + geom_histogram(aes(x=exp_log), bins=400, fill="#7eb0d5") + ggtitle("Flat pattern 1 - log transformation")

grid.arrange(a, b, ncol=2)
```

\

#### Filtro flat pattern 2

Recorrendo aos dados filtrados com o filtro 2, realizaram-se histogramas para visualizar a distribui√ß√£o dos dados (Gr√°fico da esquerda). No gr√°fico da direita, apenas se fez uma normaliza√ß√£o dos dados com log transformation de modo a poder visualizar melhor a distribui√ß√£o, que aparenta estar enviesada √† esquerda.

```{r, fig.width = 12, message=F}
# Filtro flat pattern 2
a <- ggplot(mean_exp_f2) + geom_histogram(aes(x=exp), bins=200, fill="#7eb0d5") + ggtitle("Flat pattern 2")
b <- ggplot(mean_exp_f2) + geom_histogram(aes(x=exp_log), bins=200, fill="#7eb0d5") + ggtitle("Flat pattern 2 - log transformation")

grid.arrange(a, b, ncol=2)
```

\

#### Ontologia de genes

```{r, fig.width = 9, message=F}
# 20 genes mais expressos
all_genes_means <- data.frame(gene_id=c(rownames(gene_data_nona)),exp=apply(gene_data_nona, 1, mean))
all_genes_means <- all_genes_means[order(all_genes_means$exp, decreasing=T),]
high_20 <- head(all_genes_means, n=20)

# Visualiza√ß√£o das fun√ß√µes
go_prof <- gost(high_20$gene_id, organism = "hsapiens")
gostplot(go_prof, capped=F, interactive = T)
```

O gr√°fico seguinte representa a ontologia dos 20 genes mais expressos. Cada c√≠rculo representa uma correspond√™ncia de um gene a uma das suas fun√ß√µes. Genes podem estar associados a mais do que uma fun√ß√£o. Duas das ontologias com maior representa√ß√£o pelos genes mais expressos s√£o de componentes celulares (<GO:CC>) e processos biol√≥gicos (<GO:BP>).\


## **3. An√°lise Univariada**
```{r, fig.width=12}

# Preparar dados cl√≠nicos e fatores
clean_data_for_2part <- clini_data_no_na

f_ancestralidade <- as.factor(clean_data_for_2part$sex)
names(f_sex) <- clean_data_for_2part$sample_ID

f_cancer <- as.factor(clean_data_for_2part$cancer_type)
names(f_cancer) <- clean_data_for_2part$sample_ID

f_ancestralidade <- as.factor(clean_data_for_2part$ancestry)
names(f_ancestralidade) <- clean_data_for_2part$sample_ID

f_survival <- as.factor(clean_data_for_2part$surv_status)
names(f_survival) <- clean_data_for_2part$sample_ID

fatores <- list(
  Sexo = f_sex,
  TipoTumor = f_cancer,
  Ancestralidade = f_ancestralidade,
  Sobrevivencia = f_survival
)

# Express√£o log2-CPM
log_cpm <- cpm(d0_f, log = TRUE)

# Inicializar vari√°veis
resultados_df <- data.frame()
plot_list <- list()
i <- 1

# Loop por genes e vari√°veis cl√≠nicas
for (gene_id in high_20$gene_id) {
  for (nome_var in names(fatores)) {
    grupo <- fatores[[nome_var]]
    amostras_comuns <- intersect(colnames(log_cpm), names(grupo))
    if (length(amostras_comuns) < 2) next

    grupo_valid <- grupo[amostras_comuns]
    expr <- log_cpm[as.character(gene_id), amostras_comuns]

    if (length(unique(grupo_valid)) < 2) next

    df_plot <- data.frame(expr = expr, grupo = grupo_valid)

    # Boxplot
    p <- ggplot(df_plot, aes(x = grupo, y = expr, fill=grupo)) +
      geom_boxplot() +
      scale_fill_manual(values = palette_3) + theme_bw() +
      labs(title = paste(gene_id, "-", nome_var), x = nome_var, y = "Log2 CPM")

    plot_list[[i]] <- p
    i <- i + 1

    # Teste estat√≠stico
    p_val <- if (length(unique(grupo_valid)) == 2) {
      t.test(expr ~ grupo_valid)$p.value
    } else {
      summary(aov(expr ~ grupo_valid))[[1]][["Pr(>F)"]][1]
    }

    resultados_df <- rbind(resultados_df, data.frame(
      gene = gene_id,
      variavel_clinica = nome_var,
      p_value = p_val
    ))
  }
}

# Mostrar os boxplots em grupos de 4 com espa√ßos para coment√°rios
text_chunks <- c(
  "Express√£o muito elevada e bastante est√°vel entre os grupos. N√£o h√° varia√ß√µes vis√≠veis relevantes por sexo, tipo tumoral ou sobreviv√™ncia.",
  "Apresenta express√£o mais elevada em um subtipo tumoral espec√≠fico. Discreta varia√ß√£o por ancestralidade.",
  "Tipo tumoral mostra-se como principal fator diferenciador; as restantes vari√°veis n√£o apresentam padr√µes marcantes.",
  "Diferen√ßa clara entre subtipos tumorais. Leves varia√ß√µes por sexo e ancestralidade, mas n√£o significativas.",
  "Padr√£o consistente com maior express√£o em um subtipo tumoral. Outras vari√°veis sem impacto aparente.",
  "Varia√ß√£o moderada por tipo tumoral e ancestralidade. N√£o se observa tend√™ncia clara por sexo ou sobreviv√™ncia.",
  "Diferen√ßa acentuada por tipo tumoral; demais vari√°veis com distribui√ß√£o bastante homog√™nea.",
  "Express√£o globalmente elevada, com destaque para separa√ß√£o clara por tipo de tumor.",
  "Maior dispers√£o na express√£o entre ancestrais, embora n√£o significativa. Tipo tumoral novamente com maior impacto.",
  "Leve tend√™ncia por tipo tumoral, mas de forma mais subtil. Restantes vari√°veis sem separa√ß√£o vis√≠vel.",
  "Tipo tumoral volta a ser a √∫nica vari√°vel com alguma separa√ß√£o. Sexo e sobreviv√™ncia com padr√£o est√°vel.",
  "Diferen√ßa n√≠tida entre os subtipos tumorais. As outras vari√°veis mant√™m distribui√ß√£o semelhante.",
  "Maior express√£o em determinado tipo de tumor. Pouca varia√ß√£o por sexo, ancestralidade ou sobreviv√™ncia.",
  "Tipo tumoral como principal discriminador. Ancestralidade com leve dispers√£o, sem valor significativo.",
  "Express√£o moderadamente vari√°vel por subtipo tumoral. Restantes categorias com sobreposi√ß√£o consider√°vel.",
  "Leves diferen√ßas entre subgrupos tumorais e ancestrais, sem separa√ß√µes fortes.",
  "Tipo tumoral mostra padr√£o relevante; n√£o h√° qualquer padr√£o aparente por sexo ou estado de sobreviv√™ncia.",
  "Express√£o consistente entre subgrupos. Nenhuma vari√°vel apresenta distin√ß√£o marcada.",
  "Varia√ß√£o estatisticamente significativa por tipo tumoral. Demais vari√°veis com comportamento uniforme.",
  "Separa√ß√£o clara entre subtipos de tumor. Sexo e sobreviv√™ncia com pouca ou nenhuma relev√¢ncia vis√≠vel."
)

for (i in seq(1, length(plot_list), by = 4)) {
  section_num <- ceiling(i / 4)
  plot_set <- plot_list[i:min(i+3, length(plot_list))]
  plot_set <- plot_set[!sapply(plot_set, is.null)]
  
  if (length(plot_set) > 0) {
    grid.arrange(grobs = plot_set, ncol = 2, nrow = 2)
  }
  if (section_num <= length(text_chunks)) {
    html_chunk <- HTML(paste0(
      '<div style="background-color:#e6f2ff; padding:10px; border-left:5px solid #337ab7; margin-top:10px; margin-bottom:10px;">',
      text_chunks[section_num],
      '</div>'
    ))
    print(html_chunk)
  }
}
# Mostrar p-values em tabela
datatable(resultados_df, caption = "p-values da an√°lise univariada", options = list(pageLength = 10))
```

De forma geral, a vari√°vel tipo tumoral √© consistentemente a que mais distingue a express√£o dos genes analisados, sendo respons√°vel pela maior parte das separa√ß√µes vis√≠veis nos boxplots. Sexo, ancestralidade e estado de sobreviv√™ncia raramente apresentam varia√ß√µes relevantes entre grupos. Estes resultados refor√ßam que, entre os 20 genes mais expressos, o perfil transcript√¥mico est√° fortemente relacionado ao subtipo tumoral, com impacto reduzido de fatores demogr√°ficos ou cl√≠nicos mais amplos.

## **4. An√°lise de Express√£o Diferencial**
```{r}
for (nome_var in names(fatores)) {
  cat("\n\n### Analisando express√£o diferencial para:", nome_var, "###\n")

  fator <- fatores[[nome_var]]
  amostras_comuns <- intersect(colnames(d0_f), names(fator))
  grupo <- fator[amostras_comuns]
  y <- d0_f[, amostras_comuns]
  grupo <- droplevels(grupo[!is.na(grupo)])
  y <- y[, names(grupo)]

  if (length(unique(grupo)) < 2) next

  design <- model.matrix(~ grupo)
  colnames(design) <- make.names(colnames(design))
  y <- estimateDisp(y, design)
  fit <- glmQLFit(y, design)
  qlf <- glmQLFTest(fit, coef = 2)
  top_genes <- topTags(qlf, n = Inf)
  topGenesTable <- top_genes$table
  topGenesTable$threshold <- as.factor(abs(topGenesTable$logFC) > 1 & topGenesTable$FDR < 0.05)

  print(ggplot(topGenesTable, aes(x = logFC, y = -log10(FDR), color = threshold)) +
          geom_point(alpha = 0.6) +
          scale_color_manual(values = c("grey", "red")) +
          theme_bw() +
          ggtitle(paste("Volcano plot -", nome_var)))

  cat("Total de DEGs com FDR < 0.05 e |logFC| > 1:", sum(topGenesTable$threshold == TRUE), "\n")
  datatable(head(topGenesTable[topGenesTable$threshold == TRUE, ], 20), caption = paste("Top DEGs -", nome_var))
}
```

A an√°lise de express√£o diferencial foi realizada com o objetivo de identificar genes diferencialmente expressos (DEGs) entre os diferentes grupos definidos por vari√°veis cl√≠nicas. Para garantir a signific√¢ncia estat√≠stica e a relev√¢ncia biol√≥gica dos resultados, foram aplicados filtros com FDR < 0.05 e |log2(Fold Change)| > 1.

**Sexo:**

No caso da vari√°vel sexo, foram identificados apenas 4 genes diferencialmente expressos. Este n√∫mero reduzido √© consistente com o facto de a maioria dos genes expressos em tumores cerebrais n√£o apresentar varia√ß√£o significativa entre indiv√≠duos do sexo masculino e feminino. Os genes detetados podem estar associados a mecanismos relacionados com cromossomas sexuais ou regula√ß√£o hormonal, mas o impacto global do sexo na express√£o gen√©tica revelou-se limitado.

**Tipo de Tumor:**

Para a vari√°vel tipo de tumor, foram identificados 129 DEGs, evidenciando um impacto consider√°vel desta caracter√≠stica cl√≠nica na express√£o gen√©tica. A compara√ß√£o entre os subtipos tumorais revelou perfis de express√£o distintos, com genes significativamente up e down-regulados. Estes resultados indicam que o tipo de tumor influ√™ncia fortemente o comportamento molecular das c√©lulas tumorais, podendo refletir diferen√ßas nos mecanismos de progress√£o, agressividade ou resposta ao tratamento.

**Ancestralidade:**

Relativamente √† ancestralidade, foram identificados 13 genes diferencialmente expressos. Apesar de ser um n√∫mero modesto, sugere que existem algumas diferen√ßas no perfil de express√£o gen√©tica entre grupos populacionais distintos, possivelmente relacionadas com variantes gen√©ticas herdadas. Estes resultados podem ter implica√ß√µes no entendimento da predisposi√ß√£o gen√©tica e na personaliza√ß√£o de abordagens terap√™uticas.

**Sobrevivencia:**

Por fim, a vari√°vel sobreviv√™ncia revelou-se a que apresentou o maior n√∫mero de genes diferencialmente expressos, com um total de 202 DEGs. Esta associa√ß√£o forte entre o perfil de express√£o gen√©tica e o tempo de sobreviv√™ncia dos pacientes sugere a exist√™ncia de assinaturas moleculares com potencial valor progn√≥stico. Os genes identificados poder√£o estar envolvidos em processos biol√≥gicos associados √† progress√£o tumoral, resposta imune ou resist√™ncia terap√™utica.


## **5. Enriquecimento Funcional**
```{r enriquecimento-funcional, message=FALSE, warning=FALSE, fig.width=8, fig.height=5, results='asis'}

# Loop por cada vari√°vel categ√≥rica
for (nome_var in names(fatores)) {
  cat(paste0("\n\n### Enriquecimento funcional para: ", nome_var, " ###\n"))
  
  # Subconjunto de amostras e fatores
  fator <- fatores[[nome_var]]
  amostras_comuns <- intersect(colnames(d0_f), names(fator))
  grupo <- droplevels(fator[amostras_comuns])
  
  if (length(unique(grupo)) < 2) {
    cat("Fator sem pelo menos 2 grupos distintos. Pulando.\n")
    next
  }

  y <- d0_f[, names(grupo)]
  design <- model.matrix(~ grupo)
  y <- estimateDisp(y, design)
  fit <- glmQLFit(y, design)
  qlf <- glmQLFTest(fit, coef = 2)
  
  top_genes <- topTags(qlf, n = Inf)
  deg_table <- top_genes$table
  deg_genes <- deg_table[deg_table$FDR < 0.05 & abs(deg_table$logFC) > 1, ]
  
  entrez_ids <- rownames(deg_genes)
  entrez_ids <- entrez_ids[!is.na(entrez_ids)]

  cat("Total de genes diferenciais para enriquecimento:", length(entrez_ids), "\n\n")

  if (length(entrez_ids) > 10) {
    ## GO: Biological Processes
    ego <- enrichGO(
      gene = entrez_ids,
      OrgDb = org.Hs.eg.db,
      keyType = "ENTREZID",
      ont = "BP",
      pAdjustMethod = "BH",
      qvalueCutoff = 0.05,
      readable = TRUE
    )

    if (!is.null(ego) && nrow(as.data.frame(ego)) > 0) {
      cat("**Dotplot GO - Processos Biol√≥gicos:**\n")
      print(dotplot(ego, showCategory = 20) +
              theme(axis.text.y = element_text(size = 10)) +
              scale_y_discrete(labels = function(x) str_wrap(x, width = 40)))
      
      datatable(as.data.frame(ego)[, 1:6], 
                caption = paste("Termos GO enriquecidos -", nome_var), 
                options = list(pageLength = 10))
    } else {
      cat("Sem termos GO significativos.\n")
    }

    ## KEGG Pathways
    ekegg <- enrichKEGG(
      gene = entrez_ids,
      organism = 'hsa',
      pAdjustMethod = "BH",
      qvalueCutoff = 0.05
    )

    if (!is.null(ekegg) && nrow(as.data.frame(ekegg)) > 0) {
      cat("**Dotplot KEGG - Vias metab√≥licas:**\n")
      print(dotplot(ekegg, showCategory = 20) +
              theme(axis.text.y = element_text(size = 10)) +
              scale_y_discrete(labels = function(x) str_wrap(x, width = 40)))
      
      datatable(as.data.frame(ekegg)[, 1:6], 
                caption = paste("Vias KEGG enriquecidas -", nome_var), 
                options = list(pageLength = 10))
    } else {
      cat("Sem vias KEGG significativas.\n")
    }

  } else {
    cat("Genes insuficientes para enriquecimento funcional.\n")
  }

  cat("\n\n---\n\n")
}
```


Ap√≥s a identifica√ß√£o dos genes diferencialmente expressos (DEGs), foi realizada uma an√°lise de enriquecimento funcional com base nas listas de genes significativos obtidas para cada vari√°vel cl√≠nica. Esta an√°lise teve como objetivo identificar termos de ontologia gen√©tica (GO) ou vias de sinaliza√ß√£o (como KEGG), que se encontram explicitamente representados nos gr√°ficos gerados.

**Sexo**

A an√°lise de enriquecimento funcional para os genes diferencialmente expressos entre sexos revelou um n√∫mero reduzido de termos significativamente enriquecidos, o que est√° de acordo com o baixo n√∫mero de DEGs (4), impossibilitando a realiza√ß√£o da an√°lise de enriquecimento. Os poucos processos identificados est√£o provavelmente associados a fun√ß√µes ligadas aos cromossomas sexuais ou regula√ß√£o hormonal, refletindo as diferen√ßas biol√≥gicas subtis entre indiv√≠duos do sexo masculino e feminino. A aus√™ncia de vias altamente representadas sugere que o sexo tem um impacto limitado nos mecanismos celulares globais, pelo menos no contexto dos tumores analisados.

**Tipo de Tumor**

Para a vari√°vel tipo de tumor, o gr√°fico apresentou uma maior densidade de termos significativos. Estavam visivelmente destacados termos como "extracellular matrix organization", "collagen fibril organization", "angiogenesis", "cell adhesion" e "response to hypoxia". Estes termos indicam que os genes diferencialmente expressos entre os tipos tumorais est√£o fortemente associados a processos extracelulares, estruturais e de resposta a altera√ß√µes no ambiente celular, como a hip√≥xia. Estes resultados indicam que diferentes tipos de tumor apresentam perfis moleculares distintos, refletindo varia√ß√µes nos mecanismos biol√≥gicos subjacentes, o que poder√° ser relevante para a defini√ß√£o de terapias direcionadas.

**Ancestralidade**

Apesar de ter um n√∫mero relativamente baixo de DEGs (13), a an√°lise evidenciou alguns termos significativamente enriquecidos. Os genes diferencialmente expressos parecem estar envolvidos em processos metab√≥licos espec√≠ficos e resposta imune, sugerindo que a ancestralidade pode influenciar mecanismos biol√≥gicos subtis que, embora n√£o dominantes, podem contribuir para varia√ß√µes fenot√≠picas observadas entre popula√ß√µes. Este resultado refor√ßa a import√¢ncia da diversidade gen√©tica na investiga√ß√£o.

**Sobreviv√™ncia**

Finalmente, a vari√°vel sobreviv√™ncia apresentou o maior n√∫mero de termos enriquecidos, vis√≠veis numa lista densa no gr√°fico correspondente. Os termos mais destacados foram "cell cycle", "mitotic nuclear division", "DNA replication", "chromosome segregation" e "regulation of cell proliferation". Estes termos sugerem, de forma clara pelas legendas, que os genes associados √† sobreviv√™ncia est√£o envolvidos em processos celulares fundamentais ligados √† divis√£o celular e √† prolifera√ß√£o. Estes resultados apontam para uma forte associa√ß√£o entre a express√£o g√©nica e o progn√≥stico cl√≠nico dos pacientes, sugerindo a exist√™ncia de potenciais assinaturas moleculares com valor progn√≥stico e poss√≠veis alvos terap√™uticos.



## **6. An√°lise PCA**
```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=5, results='asis'}
# Usar todos os genes da matriz de express√£o
expr_all <- log_cpm  # log2 CPM

# Transpor: linhas = amostras, colunas = genes
expr_all_t <- t(expr_all)

# PCA
pca_res <- prcomp(expr_all_t, scale. = TRUE)

# Criar diret√≥rio para salvar resultados se necess√°rio
dir.create("resultados_PCA", showWarnings = FALSE)

# Loop pelas vari√°veis cl√≠nicas
for (nome_var in names(fatores)) {
  cat("### PCA para:", nome_var, "\n\n")
  
  grupo_var <- fatores[[nome_var]]
  
  # Alinhar amostras
  amostras_comuns <- intersect(rownames(expr_all_t), names(grupo_var))
  
  if (length(amostras_comuns) < 2) {
    cat("Vari√°vel", nome_var, "n√£o tem amostras suficientes. Pulando.\n\n")
    next
  }
  
  grupo_valid <- grupo_var[amostras_comuns]
  grupo_valid <- as.factor(grupo_valid)
  
  if (length(unique(grupo_valid)) < 2) {
    cat("Vari√°vel", nome_var, "n√£o tem pelo menos 2 grupos distintos. Pulando.\n\n")
    next
  }
  
  # Preparar dados PCA para o gr√°fico
  pca_data <- as.data.frame(pca_res$x[amostras_comuns, 1:2])
  pca_data$grupo <- grupo_valid
  
  # Gr√°fico PCA
  p <- ggplot(pca_data, aes(x = PC1, y = PC2, color = grupo)) +
    geom_point(size = 3, alpha = 0.8) +scale_fill_manual(values = palette_3) + theme_bw() +
    labs(title = paste("PCA -", nome_var),
         x = "PC1", y = "PC2")
    
  
  print(p)  # Mostrar no HTML

  cat("\n\n---\n\n")  # Separador entre gr√°ficos no relat√≥rio
}
```


A An√°lise de Componentes Principais (PCA) foi aplicada com o objetivo de reduzir a dimensionalidade dos dados de express√£o g√™nica e identificar padr√µes de varia√ß√£o global entre as amostras. Esta t√©cnica estat√≠stica transforma um conjunto de vari√°veis possivelmente correlacionadas em um novo conjunto de vari√°veis n√£o correlacionadas, denominadas componentes principais. A partir disso, foi poss√≠vel visualizar a distribui√ß√£o das amostras segundo vari√°veis cl√≠nicas relevantes, como sexo, tipo tumoral, ancestralidade e estado de sobreviv√™ncia, facilitando a identifica√ß√£o de poss√≠veis agrupamentos e rela√ß√µes entre os dados.

**Sexo**

O gr√°fico mostra dois grupos parcialmente sobrepostos ao longo dos componentes principais PC1 e PC2. N√£o h√° uma separa√ß√£o clara entre os sexos, o que indica que, com base na express√£o global dos genes, n√£o existe uma forte varia√ß√£o entre os grupos masculino e feminino. Portanto, o sexo n√£o parece ser um fator determinante nos principais padr√µes de varia√ß√£o da express√£o gen√©tica nesse conjunto de dados.

**TipoTumor**

Neste gr√°fico, observa-se uma separa√ß√£o mais evidente entre os subtipos tumorais. Os grupos ocupam regi√µes distintas no plano PC1 vs. PC2, o que sugere que o tipo de tumor est√° associado a varia√ß√µes expressivas no perfil transcript√¥mico. Isso refor√ßa a ideia de que os subtipos de LGG possuem assinaturas moleculares distintas, consistentes com a heterogeneidade molecular previamente descrita no trabalho.

**Ancestralidade**

Apesar de uma predomin√¢ncia de indiv√≠duos com ancestralidade europeia, o gr√°fico revela alguma sobreposi√ß√£o entre os grupos, com tend√™ncia a agrupamentos por ancestralidade. Isto indica que pode haver varia√ß√µes gen√¥micas associadas √† ancestralidade, embora o impacto sobre a express√£o global pare√ßa menos acentuado do que no caso do tipo tumoral.

**Sobreviv√™ncia**

O gr√°fico mostra alta sobreposi√ß√£o entre os grupos de sobreviv√™ncia (vivo com/sem tumor e morto com tumor). Isso sugere que, com base apenas nos dois primeiros componentes principais, o status de sobreviv√™ncia n√£o √© fortemente refletido no padr√£o global de express√£o gen√©tica. √â poss√≠vel que diferen√ßas mais discretas estejam presentes em componentes secund√°rios ou em subconjuntos de genes espec√≠ficos.

```{r, echo=F}
palette_3 <- c("#fd7f6f", "#7eb0d5", "#b2e061", "#bd7ebe", "#ffb55a", "#ffee65", "#beb9db", "#fdcce5", "#8bd3c7")
```

## **7. An√°lise UMAP com PC¬¥s**
```{r pca-plot, fig.height=5, fig.width=7, message=FALSE, warning=FALSE, results='asis'}

# Reduzir para 30 componentes antes do UMAP
pca_matrix <- pca_res$x[, 1:30]

# UMAP diretamente sobre os PCs
set.seed(123)  # para reprodutibilidade
umap_res <- umap(pca_matrix, n_neighbors = 15, min_dist = 0.1, metric = "euclidean")

# Converter resultado UMAP para data frame com nomes de amostras
rownames(umap_res) <- rownames(expr_all_t)
umap_df <- as.data.frame(umap_res)
colnames(umap_df) <- c("UMAP1", "UMAP2")


# Loop pelas vari√°veis cl√≠nicas 
for (nome_var in names(fatores)) {
  cat("### UMAP para:", nome_var, "\n\n")
  
  grupo_var <- fatores[[nome_var]]
  amostras_comuns <- intersect(rownames(umap_df), names(grupo_var))
  
  grupo_valid <- as.factor(grupo_var[amostras_comuns])
  umap_plot_df <- umap_df[amostras_comuns, ]
  umap_plot_df$Grupo <- grupo_valid

  # Gr√°fico
  p <- ggplot(umap_plot_df, aes(x = UMAP1, y = UMAP2, color = Grupo)) +
    geom_point(size = 3, alpha = 0.8) +
    theme_bw() +
    labs(title = paste("UMAP -", nome_var))
  
  print(p)
  
  cat("\n\n---\n\n")
}
```

O UMAP (Uniform Manifold Approximation and Projection) √© uma t√©cnica de redu√ß√£o de dimensionalidade n√£o linear que, tal como o t-SNE, √© particularmente eficaz para visualizar dados de alta dimens√£o. Baseia-se em princ√≠pios matem√°ticos da topologia e da teoria dos grafos, procurando preservar tanto a estrutura local quanto a global dos dados. Em contraste com m√©todos lineares como o PCA, o UMAP √© capaz de revelar padr√µes complexos e n√£o lineares nos dados, o que o torna especialmente √∫til para explorar agrupamentos naturais ou separa√ß√µes entre classes, sendo comum utilizar PCA numa primeira fase de pr√©-processamento de forma a reduzir o ru√≠do e acelerar c√°lculos posteriores. Neste trabalho foi assim que procedemos realizando UMAP sobre os PCs obtidos posteriormente. 

**Sexo**

Na visualiza√ß√£o UMAP baseada nos componentes principais, os grupos Female e Male apresentam uma distribui√ß√£o amplamente sobreposta. N√£o se observa uma separa√ß√£o clara entre os sexos, indicando que o fator "Sexo" n√£o exerce uma influ√™ncia dominante sobre as principais varia√ß√µes capturadas nos dados. 

**Tipo de Tumor**

Na an√°lise UMAP com base nos tipos tumorais, observam-se regi√µes parcialmente sobrepostas entre os grupos Astrocytoma, Oligoastrocytoma e Oligodendroglioma. Ainda que exista algum grau de separa√ß√£o, h√° uma interpenetra√ß√£o consider√°vel entre os grupos, indicando que as caracter√≠sticas extra√≠das n√£o s√£o completamente discriminantes neste espa√ßo reduzido. O UMAP manteve a coes√£o local de alguns subgrupos, mas a sobreposi√ß√£o sugere proximidade fenot√≠pica ou gen√¥mica entre os tumores.

**Ancestralidade**

No gr√°fico UMAP de Ancestria, os grupos AFR, EAS e SAS formam aglomerados localizados e visualmente distintos. O grupo EUR tamb√©m apresenta alguma separa√ß√£o, mas est√° mais disperso em compara√ß√£o com os demais, ocupando uma √°rea relativamente ampla. Os grupos mistos, como AFR_ADMIX, EUR_ADMIX e SAS_ADMIX, aparecem distribu√≠dos em zonas de transi√ß√£o, com sobreposi√ß√£o parcial entre si e com seus grupos de origem. Embora existam padr√µes vis√≠veis, a separa√ß√£o entre todos os grupos n√£o √© completa, e h√° regi√µes com mistura significativa.

**Sobreviv√™ncia**

Neste gr√°fico, avaliamos a separa√ß√£o dos indiv√≠duos com base no estado de sobreviv√™ncia. Nota-se alguma sobreposi√ß√£o entre os dois grupos ("ALIVE OR DEAD TUMOR FREE" vs. "DEAD WITH TUMOR"), embora existam tend√™ncias de agrupamento. Isto sugere que podem existir padr√µes moleculares ou gen√©ticos associados ao progn√≥stico, ainda que estes n√£o sejam t√£o fortemente delineados como noutros casos.


## **8. An√°lise T-SNE com PC¬¥s**
```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# t-SNE
set.seed(123)
tsne_res <- Rtsne(pca_matrix, dims = 2, perplexity = 30, verbose = FALSE)
tsne_df <- as.data.frame(tsne_res$Y)
rownames(tsne_df) <- rownames(pca_matrix)
colnames(tsne_df) <- c("tSNE1", "tSNE2")

# Loop pelas vari√°veis cl√≠nicas
for (nome_var in names(fatores)) {
  cat("### t-SNE para:", nome_var, "\n\n")
  
  grupo_var <- fatores[[nome_var]]
  amostras_comuns <- intersect(rownames(tsne_df), names(grupo_var))
  
  grupo_valid <- as.factor(grupo_var[amostras_comuns])
  tsne_plot_df <- tsne_df[amostras_comuns, ]
  tsne_plot_df$Grupo <- grupo_valid

  # Gr√°fico
  p <- ggplot(tsne_plot_df, aes(x = tSNE1, y = tSNE2, color = Grupo)) +
    geom_point(size = 3, alpha = 0.8) +
    theme_bw() + labs(title = paste("t-SNE -", nome_var))

  # Mostrar e salvar
  print(p)
  
  cat("\n\n---\n\n")
}


```
O t-SNE √© uma t√©cnica de redu√ß√£o de dimensionalidade n√£o linear que transforma dist√¢ncias entre pontos de alta dimens√£o em distribui√ß√µes de probabilidade, tanto no espa√ßo original quanto no projetado. O seu principal objetivo √© preservar as rela√ß√µes de vizinhan√ßa local, favorecendo a visualiza√ß√£o de agrupamentos. No entanto, esse foco local compromete a interpreta√ß√£o das dist√¢ncias globais e pode distorcer o posicionamento relativo entre grupos. Neste trabalho, o t-SNE foi aplicado sobre os componentes principais do PCA, visando explorar padr√µes de proximidade entre amostras com base nas caracter√≠sticas mais relevantes.

**Sexo**

O gr√°fico t-SNE para a vari√°vel Sexo mostra os grupos Female e Male altamente sobrepostos. Ambos os grupos ocupam praticamente o mesmo espa√ßo projetado, com distribui√ß√£o semelhante. N√£o h√° separa√ß√£o vis√≠vel entre os dois. A vari√°vel Sexo n√£o se diferencia visualmente neste gr√°fico.

**Tipo de Tumor**

No gr√°fico t-SNE para o Tipo de Tumor, observa-se uma separa√ß√£o visual parcial entre os grupos Oligodendroglioma e Astrocytoma, que tendem a ocupar regi√µes distintas. No entanto, os dois grupos ainda apresentam alguma proximidade nas bordas. O grupo Oligoastrocytoma aparece mais disperso e sobreposto aos outros dois, ocupando uma zona intermedi√°ria. Portanto, embora a separa√ß√£o entre os tr√™s grupos n√£o seja completa, h√° evid√™ncia visual de distin√ß√£o entre pelo menos dois deles.

**Ancestralidade**

O gr√°fico t-SNE de Ancestralidade mostra que alguns grupos como AFR, EAS e SAS formam aglomerados minimamente definidos e localizados. No entanto, o grupo EUR est√° amplamente espalhado, ocupando grande parte do espa√ßo projetado, o que dificulta a visualiza√ß√£o de fronteiras claras e evidencia uma baixa coes√£o interna. Grupos como EUR_ADMIX e outros mistos aparecem dispersos e sobrepostos em zonas de transi√ß√£o. Apesar de existirem regi√µes bem delimitadas, a domin√¢ncia visual de EUR compromete a separa√ß√£o global entre os grupos.

**Sobreviv√™ncia**

No gr√°fico t-SNE de Sobreviv√™ncia, os dois grupos ("0: ALIVE OR DEAD TUMOR FREE" e "1: DEAD WITH TUMOR") est√£o distribu√≠dos de forma misturada. H√° algumas zonas com predomin√¢ncia de um grupo, mas no geral, os dois compartilham o espa√ßo. A separa√ß√£o entre os grupos √© fraca ou inexistente na proje√ß√£o t-SNE.


## **9. UMAP vs T-SNE**

Ao aplicar tanto o UMAP como o t-SNE sobre os componentes principais obtidos atrav√©s do PCA, torna-se poss√≠vel comparar ambas as t√©cnicas de redu√ß√£o de dimensionalidade e avaliar os resultados √† luz do seu funcionamento. Esta compara√ß√£o permite, inclusive, refletir sobre qual dos m√©todos pode ser mais √∫til e vantajoso consoante o objetivo da an√°lise.

Tanto o UMAP (Uniform Manifold Approximation and Projection) quanto o t-SNE (t-distributed Stochastic Neighbor Embedding) s√£o m√©todos projetados para reduzir dados de alta dimens√£o a um espa√ßo bidimensional, facilitando a visualiza√ß√£o. Apesar de objetivos semelhantes, os dois algoritmos diferem significativamente na forma como operam e no tipo de estrutura que tendem a preservar.

Na pr√°tica, essa diferen√ßa refletiu-se nas visualiza√ß√µes obtidas: o UMAP gerou proje√ß√µes mais organizadas globalmente, com os agrupamentos dispostos de forma mais cont√≠nua no espa√ßo. J√° o t-SNE apresentou melhor separa√ß√£o local em alguns casos, como em certos subgrupos tumorais, mas tamb√©m originou distribui√ß√µes excessivamente dispersas, dificultando a interpreta√ß√£o.

Em resumo, o UMAP revelou-se mais informativo para observar rela√ß√µes globais entre grupos, enquanto o t-SNE se destacou na identifica√ß√£o de estruturas locais. Assim, a escolha entre os dois m√©todos deve considerar o foco da an√°lise: se o objetivo for explorar padr√µes locais com alta fidelidade, o t-SNE √© mais indicado; se houver interesse em manter uma vis√£o mais equilibrada entre estrutura local e global, o UMAP √© prefer√≠vel.



## **10. Clustering**

**Clustering hier√°rquico**

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Selecionar os 30 genes com menor p-value
top_30 <- head(deg_table[order(deg_table$PValue), ], 30)

# Usar rownames como identificador dos genes
gene_ids <- rownames(top_30)

# Obter dados de express√£o para os genes v√°lidos
genes_matrix <- expr_all[gene_ids, ]

# Normalizar por gene (z-score)
genes_matrix_scaled <- t(scale(t(genes_matrix)))

# Clustering hier√°rquico
dist_matrix <- dist(genes_matrix_scaled)
hc <- hclust(dist_matrix, method = "complete")

# Plotar dendrograma
plot(hc,
     main = paste("Clustering hier√°rquico de", length(gene_ids), "genes mais significativos"),
     ylab = "Dist√¢ncia Euclidiana",
     xlab = "",
     sub = "")



```
O dendrograma gerado representa o agrupamento hier√°rquico dos 30 genes mais significativos, selecionados com base nos menores valores de p-value da an√°lise de express√£o diferencial. O agrupamento foi realizado com base nos perfis de express√£o desses genes ao longo das diferentes amostras, considerando a dist√¢ncia euclidiana como medida de dissimilaridade.

A estrutura do dendrograma revela que alguns genes apresentam padr√µes de express√£o muito semelhantes entre si, sendo agrupados em n√≠veis inferiores da hierarquia, ou seja, em pontos mais baixos do eixo vertical. Isso indica que esses genes possuem comportamentos similares nas amostras analisadas, o que pode sugerir uma co-regula√ß√£o ou participa√ß√£o em processos biol√≥gicos comuns. Por exemplo, √© poss√≠vel observar a forma√ß√£o de subgrupos distintos com genes fortemente correlacionados, enquanto outros grupos se formam apenas em n√≠veis mais elevados de dist√¢ncia, indicando uma menor similaridade entre seus perfis de express√£o.

O eixo vertical do dendrograma, que representa a dist√¢ncia euclidiana, alcan√ßa valores relativamente altos (acima de 30), o que sugere uma consider√°vel variabilidade nos perfis de express√£o entre os genes analisados. Essa heterogeneidade √© esperada quando os genes selecionados atuam em diferentes vias ou processos celulares.

De forma geral, a an√°lise do dendrograma mostra que os genes mais significativamente alterados n√£o s√£o homog√™neos em sua express√£o, mas sim organizam-se em subgrupos que refletem poss√≠veis padr√µes biol√≥gicos relevantes. 

**Clustering K-means**

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Selecionar os 30 genes com menor p-value
top_30 <- head(deg_table[order(deg_table$PValue), ], 30)

# Usar rownames como identificador dos genes
gene_ids <- rownames(top_30)

# Filtrar dados de express√£o
genes_matrix <- expr_all[rownames(expr_all) %in% gene_ids, ]

# Normalizar por gene (z-score por linha)
genes_matrix_scaled <- t(scale(t(genes_matrix)))

# M√©todo do cotovelo para escolher o n√∫mero ideal de clusters
fviz_nbclust(genes_matrix_scaled, kmeans, method = "wss") +
  labs(title = "N√∫mero √≥timo de clusters\nM√©todo do Cotovelo")


set.seed(123)
k <- 3
kmeans_result <- kmeans(genes_matrix_scaled, centers = k, nstart = 25)

# Visualizar o resultado do clustering
fviz_cluster(kmeans_result, data = genes_matrix_scaled,
             main = "Clustering K-means dos 30 genes mais significativos",
             geom = "point", ellipse.type = "convex", 
             palette = palette_3,repel=TRUE)

```

**M√©todo do Cotovelo**

Para determinar o n√∫mero ideal de grupos no clustering k-means, foi utilizado o m√©todo do cotovelo, que consiste em avaliar graficamente a redu√ß√£o do erro de agrupamento √† medida que se aumenta o n√∫mero de clusters. O gr√°fico resultante apresenta, no eixo Y, a soma total dos quadrados intra-grupos (Total Within Sum of Squares), enquanto o eixo X mostra os valores testados para o n√∫mero de clusters (de 1 a 10).

A curva descendente mostra que o aumento do n√∫mero de clusters melhora a separa√ß√£o entre os genes, reduzindo a variabilidade dentro de cada grupo. No entanto, ap√≥s um determinado ponto, os ganhos adicionais tornam-se m√≠nimos. Esse ponto de inflex√£o √© conhecido como ‚Äúcotovelo‚Äù. No gr√°fico analisado, esse cotovelo ocorre por volta de k = 3, indicando que tr√™s clusters s√£o suficientes para representar bem a estrutura dos dados sem acrescentar complexidade desnecess√°ria ao modelo.

**Analise Clustering K-means**

O gr√°fico de clustering k-means com k = 3 mostra a segmenta√ß√£o dos 30 genes mais significativos com base nos seus perfis de express√£o normalizados. A proje√ß√£o dos dados em duas dimens√µes principais (Dim1 e Dim2) preserva boa parte da variabilidade, com Dim1 explicando 18.2% e Dim2 10.7%, totalizando aproximadamente 29% da informa√ß√£o original.

A aplica√ß√£o do algoritmo resultou em tr√™s grupos visualmente bem definidos:

 - Cluster 1 (azul): Apresenta distribui√ß√£o moderadamente compacta, com genes agrupados em torno de padr√µes semelhantes. Sua localiza√ß√£o no gr√°fico indica express√£o homog√™nea, mas distinta dos demais grupos.

 - Cluster 2 (amarelo): Agrupamento mais disperso, situado √† esquerda do gr√°fico. Essa dispers√£o sugere uma maior heterogeneidade entre os genes, podendo refletir perfis de express√£o mais variados ou a presen√ßa de genes com comportamento at√≠pico.

 - Cluster 3 (cinza): Ocupa uma posi√ß√£o intermedi√°ria no gr√°fico e apresenta relativa coes√£o. Pode representar genes com perfis parcialmente sobrepostos aos dos demais grupos.

A separa√ß√£o entre os tr√™s clusters refor√ßa a ideia de que os genes selecionados exibem padr√µes de express√£o diferenciados, o que pode refletir fun√ß√µes biol√≥gicas espec√≠ficas, participa√ß√£o em vias distintas ou respostas a diferentes condi√ß√µes experimentais. Essa estrutura de agrupamento pode servir como base para an√°lises funcionais mais aprofundadas, como enriquecimento de termos GO ou identifica√ß√£o de biomarcadores potenciais.




## **11. An√°lise supervisionada**
```{r message=FALSE, warning=FALSE, fig.width=12, results='asis'}

# 1. Modelos poss√≠veis 
# A. Random Forest
# B. Support Vector Machine
# c. XGBoost

# 2. Treino/teste
# A. train_test_split
# B. cross-validation

# 3. Avalia√ß√£o (m√©tricas)
# A. Accuracy
# B. F1-score
# C. AUT-ROC


# Preparar dados cl√≠nicos e fatores
clean_data_for_2part <- clini_data_no_na

f_sex <- as.factor(clean_data_for_2part$sex)
names(f_sex) <- clean_data_for_2part$sample_ID

f_cancer <- as.factor(clean_data_for_2part$cancer_type)
names(f_cancer) <- clean_data_for_2part$sample_ID

f_ancestralidade <- as.factor(clean_data_for_2part$ancestry)
names(f_ancestralidade) <- clean_data_for_2part$sample_ID

f_survival <- as.factor(clean_data_for_2part$surv_status)
names(f_survival) <- clean_data_for_2part$sample_ID

fatores <- list(
  Sexo = f_sex,
  TipoTumor = f_cancer,
  Ancestralidade = f_ancestralidade,
  Sobrevivencia = f_survival
)

# Base trainControl parameters
base_ctrl <- list(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  savePredictions = "all"
)

ctrl <- do.call(trainControl, base_ctrl)
ctrl1 <- do.call(trainControl, c(base_ctrl, list(summaryFunction = multiClassSummary)))

```


### **11.1 Random Forest**
```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## A. Random Forest com smote ---- SURVIVAL

# Verificar consist√™ncia dos dados
common_samples <- intersect(colnames(expr_all), names(f_survival))
logCPM_sub <- expr_all[, common_samples]
labels <- f_survival[common_samples]

# Criar dataframe para modelar
data_model <- as.data.frame(t(logCPM_sub))  # Genes como colunas, amostras como linhas
data_model$SurvivalStatus <- factor(labels)

# Garantir que os levels s√£o v√°lidos para SMOTE
levels(data_model$SurvivalStatus) <- make.names(levels(data_model$SurvivalStatus))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$SurvivalStatus, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Aplicar SMOTE
# Remover colunas n√£o num√©ricas
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]

# SMOTE para balancear classe
smote_result_rf <- SMOTE(trainData_numeric, trainData$SurvivalStatus, K = 3, dup_size = 2)
smote_data_rf <- smote_result_rf$data

# Ajustar nomes das colunas
colnames(smote_data_rf)[ncol(smote_data_rf)] <- "SurvivalStatus"
smote_data_rf$SurvivalStatus <- factor(smote_data_rf$SurvivalStatus, 
                                       levels = levels(trainData$SurvivalStatus))

# Treinar modelo Random Forest
set.seed(123)
fit_rf1 <- train(SurvivalStatus ~ ., data = smote_data_rf, method = "rf", 
                trControl = ctrl,
                tuneGrid = expand.grid(mtry = 2),  # Ajuste do n√∫mero de vari√°veis
                ntree = 100)  # N√∫mero de √°rvores ajustado

# Avalia√ß√£o no teste
pred_rf <- predict(fit_rf1, testData)
conf_matrix <- confusionMatrix(pred_rf, testData$SurvivalStatus)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- 171 previs√µes corretas para "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 17 previs√µes corretas para "X1.DEAD.WITH.TUMOR".
- 14 erros ao classificar "X1.DEAD.WITH.TUMOR" como "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 38 erros ao classificar "XO.ALIVE.OR.DEAD.TUMOR.FREE" como "X1.DEAD.WITH.TUMOR".
- Modelo acerta a maioria dos casos da classe "XO.ALIVE.OR.DEAD.TUMOR.FREE", mas apresenta erro significativo ao prever a classe "X1.DEAD.WITH.TUMOR", tanto por falsos negativos quanto falsos positivos.
- Existe desequilibrio na performance entre as classes, o que pode indicar vi√©s para a classe mais frequente. 
- Mesmo com SMOTE, h√° dificuldade de separa√ß√£o clara entre as clases.

M√©tricas de Desempenho:

- Accuracy: 78.33% ‚Üí Boa taxa de acertos globais.
- Kappa: 0.2757 ‚Üí Concord√¢ncia moderada a baixa entre as previs√µes e a realidade.
- Especificidade: 0.3091 ‚Üí Tem dificuldade em identificar corretamente os negativos reais.
- Balanced Accuracy: 0.6167 ‚Üí Indica desempneho desequilibrado entre sensibilidade e especificidade.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Precision, Recall, F1
positive_class <- "X0.ALIVE.OR.DEAD.TUMOR.FREE"

precision <- posPredValue(pred_rf, testData$SurvivalStatus, positive = positive_class)
recall <- sensitivity(pred_rf, testData$SurvivalStatus, positive = positive_class)
f1 <- 2 * (precision * recall) / (precision + recall)

# Print precision, recall,F1
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", round(f1, 3), "\n")
```

- Recall: 0.9243 ‚Üí Identifica 91.89% dos casos positivos corretamente.
- Precis√£o: 0.8182 ‚Üí Quando prev√™ "XO.ALIVE.OR.DEAD.TUMOR.FREE", est√° correto 81.73% das vezes.
- F1 Score: 0.868 ‚Üí Indica um bom equil√≠brio entre precis√£o e recall.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Calcular AUC e Curva ROC
roc_curve <- roc(testData$SurvivalStatus, as.numeric(pred_rf))
auc_score <- auc(roc_curve)
print(paste("AUC Score:", auc_score))

plot(roc_curve, col = palette_3, main = "ROC Curve for Random Forest (com SMOTE)")
```

Forma da Curva:

- A curva ROC est√° acima da linha diagonal, mas n√£o perfeitamente colada ao canto superior esquerdo. Isso significa que o modelo √© melhor que o acaso, mas n√£o excelente em todas as faixas de sensibilidade/especificidade.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5).
- A curva ROC do modelo est√° consistentemente acima, o que confirma capacidade preditiva real e a dist√¢ncia em rela√ß√£o √† diagonal n√£o √© t√£o grande quanto o ideal (AUC > 0.8).

AUC Score:

- AUC: 0.6167 ‚Üí O modelo tem capacidade razo√°vel de discrimica√ß√£o entre classes, mas est√° abaixo do ideal (abaixo de 0.8).

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Ver import√¢ncia dos genes
importance <- varImp(fit_rf1)

# Extract variable importance as data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Select top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 22944, com um peso de 100. Este gene tem um impacto significativo na classifica√ß√£o do modelo.
- Os primeiros 5 genes t√™m import√¢ncia consider√°vel (acima de 60), sugerindo que h√° fortes fatores gen√©ticos associados √† sobrevivi√™ncia com ou sem tumor

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Visualizar distribui√ß√£o de probabilidades
prob_rf <- predict(fit_rf1, testData, type = "prob")
boxplot(prob_rf[,1] ~ testData$SurvivalStatus, col = palette_3, 
        main = "Class Probability Distribution", ylab = "Predicted Probability")
```
Boxplot - Distribui√ß√£o das Probabilidades:

Classe "X0.ALIVE.OR.DEAD.TUMOR.FREE" (vermelho):

- A maioria das previs√µes tem probabilidades acima de 0.75, indicando alta confian√ßa do modelo nesta classe.
- Existem outliers abaixo de 0.45, mostrando ambiguidade em alguns casos, mas n√£o predominante.

Classe "X1.DEAD.WITH.TUMOR" (azul):

- A distribui√ß√£o √© mais espalhada, com valores variando de 0.45 a 0.7.
- A mediana est√° pr√≥xima de 0.6, revelando que o modelo n√£o tem muita certeza ao prever essa classe. Existem muitos casos amb√≠guos, o que contribui para os erros observados na matriz de confus√£o.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

## A. Random Forest com SMOTE ---- SEX

# Verificar consist√™ncia dos dados
common_samples <- intersect(colnames(expr_all), names(f_sex))
logCPM_sub <- expr_all[, common_samples]
labels <- f_sex[common_samples]

# Criar dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))
data_model$Sex <- factor(labels)

# Garantir que os niveis s√£o v√°lidos para SMOTE
levels(data_model$Sex) <- make.names(levels(data_model$Sex))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Sex, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Aplicar SMOTE
# Remover colunas n√£o num√©ricas
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]

# SMOTE para balancear classe
smote_result_rf <- SMOTE(trainData_numeric, trainData$Sex, K = 3, dup_size = 2)
smote_data_rf <- smote_result_rf$data

# Ajustar nomes das colunas
colnames(smote_data_rf)[ncol(smote_data_rf)] <- "Sex"
smote_data_rf$Sex <- factor(smote_data_rf$Sex, levels = levels(trainData$Sex))

# Treinar modelo Random Forest
set.seed(123)
fit_rf2 <- train(Sex ~ ., data = smote_data_rf, method = "rf", 
                trControl = ctrl, 
                tuneGrid = expand.grid(mtry = 2),
                ntree = 100)

# Avalia√ß√£o no teste
pred_rf <- predict(fit_rf2, testData)
conf_matrix <- confusionMatrix(pred_rf, testData$Sex)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de confus√£o:

- 73 previs√µes corretas para "Female" e 38 previs√µes corretas para "Male".
- 96 erros ao classificar "Female" como "Male".
- 33 erros ao classificar "Male" como "Female".

Modelo acerta menos de metade da classe "Female" e possui um desempenho ligeiramente melhor para a classe "Male", mas esta longe de ser ideal. 
A aplica√ß√£o de SMOTE n√£o foi suficiente para corrigir o desequ√≠librio ou melhorar o desempenho

M√©tricas de Desempenho:

- Accuracy: 46.25% ‚Üí o modelo acerta menos de metade de todos os casos.
- Kappa: -0.02612 ‚Üí desempenho abaixo do modelo aleat√≥rio.
- Especificidade: 0.2836 ‚Üí o modelo tem dificuldade em reconhecer a classe "Male".

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# F1, Recall, precision
testData$Sex <- factor(testData$Sex)                       
pred_rf <- factor(pred_rf, levels = levels(testData$Sex))  

# Define positive class
positive_class <- "Female"

# Check precision e recall para classe positiva
precision <- posPredValue(pred_rf, testData$Sex, positive = positive_class)
recall <- sensitivity(pred_rf, testData$Sex, positive = positive_class)

# Print precision e recall
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
```

- Precis√£o: 0.432 ‚Üí Quando o modelo prev√™ "Female", est√° correto 43.2% das vezes.
- Recall: 0.6887 ‚Üí Identifica 68.87% dos casos "Female" corretamente.
- F1 Score: 0.5309 ‚Üí Indica um modelo que n√£o √© equilibrado nem eficaz.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# F1 score
if (!is.na(precision) && !is.na(recall) && (precision + recall) > 0) {
  f1 <- 2 * (precision * recall) / (precision + recall)
  cat("F1 Score:", round(f1, 3), "\n")
} else {
  cat("F1 Score cannot be computed due to missing precision or recall.\n")
}

# Calcular AUC e Curva ROC
roc_curve <- roc(testData$Sex, as.numeric(pred_rf))
auc_score <- auc(roc_curve)
print(paste("AUC Score:", auc_score))

plot(roc_curve, col = palette_3, main = "ROC Curve for Random Forest (com SMOTE)")
```

Forma da Curva:

- A curva est√° abaixo da diagonal, indicando desempenho aleat√≥rio, o que reflete incapacidade do modelo em distinguir corretamente entre as classes.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva do modelo est√° abaixo da diagonal, o modelo tem desempenho inferior ao acaso, o que √© um forte sinal de alerta.

AUC Score:

- AUC: 0.4861 ‚Üí N√£o consegue separar eficazmente as classes "Female" e "Male"


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Ver import√¢ncia dos genes
importance <- varImp(fit_rf2)

# Extrair variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 8226 com um peso de 100 e 7317 com um peso de 99, os quais dominam completamente a decis√£o do modelo.
- Outros genes contribuem em menor escala, refor√ßando que a classifica√ß√£o depende fortemente de um gene espec√≠fico.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Visualizar distribui√ß√£o de probabilidades
prob_rf <- predict(fit_rf2, testData, type = "prob")
boxplot(prob_rf[,1] ~ testData$Sex, 
        col = palette_3, 
        main = "Class Probability Distribution", ylab = "Predicted Probability")


```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe "Female" (vermelho):

- Possui uma mediana perto dos 0.55.
- Raros outliers acima de 0.8, que indicam casos menos certos, mas ainda dentro da margem esperada

Classe "Male" (azul):

- Possui uma mediana de 0.55.
- Poucos outliers acima de 0.8.

A proximidade entre as distribui√ß√µes de probabilidade para "Female" e "Male" mostra que o modelo tem dificuldade em separar as classes com confian√ßa. 

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

## A. Random Forest com SMOTE ---- Ancestralidade

# Verificar consist√™ncia dos dados
common_samples <- intersect(colnames(expr_all), names(f_ancestralidade))
logCPM_sub <- expr_all[, common_samples]
labels <- f_ancestralidade[common_samples]

# Criar dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  
data_model$Ancestralidade <- factor(labels)

# Garantir que os levels s√£o v√°lidos para SMOTE
levels(data_model$Ancestralidade) <- make.names(levels(data_model$Ancestralidade))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Ancestralidade, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Conta ocorrencias por classe
class_counts <- table(trainData$Ancestralidade)

# Filtrar classes <= 5 samples
valid_classes <- names(class_counts[class_counts >= 5])
trainData <- trainData[trainData$Ancestralidade %in% valid_classes, ]

# Niveis fatoriais atualizados
trainData$Ancestralidade <- factor(trainData$Ancestralidade)

# Smote
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
min_class_size <- min(table(trainData$Ancestralidade))
K_value <- max(1, min_class_size - 1)

smote_result_rf <- SMOTE(trainData_numeric, trainData$Ancestralidade, K = K_value, dup_size = 2)
smote_data_rf <- smote_result_rf$data

colnames(smote_data_rf)[ncol(smote_data_rf)] <- "Ancestralidade"
smote_data_rf$Ancestralidade <- factor(smote_data_rf$Ancestralidade, levels = levels(trainData$Ancestralidade))
smote_data_rf <- na.omit(smote_data_rf)


# Treinar modelo Random Forest
set.seed(123)
fit_rf3 <- train(Ancestralidade ~ ., data = smote_data_rf, method = "rf", 
                trControl = ctrl1,
                tuneGrid = expand.grid(mtry = 2),
                ntree = 100)

# Avalia√ß√£o no teste
pred_rf <- predict(fit_rf3, testData)
true_labels <- testData$Ancestralidade

# Confusion Matrix
all_levels <- union(levels(factor(pred_rf)), levels(factor(true_labels)))
pred_rf <- factor(pred_rf, levels = all_levels)
true_labels <- factor(true_labels, levels = all_levels)
conf_matrix <- confusionMatrix(pred_rf, true_labels)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- 218 previs√µes corretas para "EUR", mas teve dificuldades nas outras classes.
- Confirma que o modelo est√° enviesado para prever EUR corretamente, mas falha nas outras classes

M√©tricas de Desempenho:

- Accuracy: 0.9121 ‚Üí Alta taxa, no entanto esta enviasada pela domin√¢ncia da classe "EUR".
- AccuracyLower: 0.8688 e AccuracyUpper: 0.9448 ‚Üí accuracy real do modelo pode variar nesse intervalo que representa uma boa estabilidade no desempenho
- AccuracyNull: 0.9121 ‚Üí o modelo pode estar apenas a prever a classe dominante.
- Kappa: 0 ‚Üí indica que o modelo n√£o est√° a prever melhor do que um classificador aleat√≥rio.
- Especificidade: 0 ‚Üí N√£o identifica corretamente os casos negativos.
- Balanced Accuracy: 0.5 ‚Üí total desequil√≠brio entre classes.
- p-value da accuracy (0.5577) indica que n√£o h√° diferen√ßa estat√≠stica significativa entre o modelo e um classificador aleat√≥rio.
- McNemarPValue est√° como NA, o que pode indicar que o teste n√£o foi realizado ou n√£o √© aplic√°vel neste caso.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Calcular m√©tricas por classe
precision_vec <- diag(conf_matrix$table) / colSums(conf_matrix$table)
recall_vec <- diag(conf_matrix$table) / rowSums(conf_matrix$table)
f1_vec <- ifelse((precision_vec + recall_vec) > 0,
                 2 * (precision_vec * recall_vec) / (precision_vec + recall_vec),
                 NA)

f1_scores <- data.frame(
  Class = rownames(conf_matrix$table),
  Precision = round(precision_vec, 3),
  Recall = round(recall_vec, 3),
  F1 = round(f1_vec, 3)
)

# Mostrar tabela de m√©tricas
knitr::kable(f1_scores, caption = "Precision, Recall, and F1 Score per Class")
```

- Precis√£o: 0.9121 ‚Üí Prev√™ apenas a classe "EUR" com alta confian√ßa.
- Recall: 1 ‚Üí Identifica bem apenas a classe "EUR".
- F1 Score: 0.954  ‚Üí Indica um score muito alto, pois reflete apenas a performance da classe dominante.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
roc_curve <- roc(testData$Ancestralidade, as.numeric(pred_rf))
auc_score <- auc(roc_curve)
print(paste("AUC Score:", auc_score))
plot(roc_curve, col = palette_3, main = "ROC Curve for Random Forest (com SMOTE)")
```

Forma da Curva:

- A curva ROC tem um degrau simples, sobre a linha diagonal, sem separa√ß√£o clara entre classes.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). A curva do Random Forest est√° nessa linha, sugerindo que o modelo tem um desempenho limitado, com discrimina√ß√£o m√≠nima apenas para a classe "EUR"

AUC Score:

- AUC: 0.5 ‚Üí o modelo tem desempenho igual ao acaso, sem valor preditivo real.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Import√¢ncia dos genes
importance <- varImp(fit_rf3)

# Extra√ß√£o variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 114880 com um peso de 100.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.07), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo. 
- O modelo pode estar dependente de poucos genes-chave, enquanto outros t√™m impacto reduzido. Isso pode indicar que algumas caracter√≠sticas podem ser removidas sem afetar o desempenho.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Visualiza√ß√£o da distribui√ß√£o de probabilidades 
prob_rf <- predict(fit_rf3, testData, type = "prob")
boxplot(prob_rf[,1] ~ testData$Ancestralidade, col = palette_3, 
        main = "Class Probability Distribution", ylab = "Predicted Probability")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe AFR:

- A mediana da probabilidade predita est√° pr√≥xima de 0.08.
- O intervalo interquartil (IQR) varia entre aproximadamente 0.075 e 0.011, indicando baixa dispers√£o.
- N√£o h√° outliers, sugerindo que o modelo prev√™ esta classe de forma consistente mas com baixa confian√ßa.

Outras classes:

- AFR_ADMIX tem distribui√ß√£o levemente mais ampla, mas ainda com baixa mediana (~0.05). 
- AMR apresenta maior varia√ß√£o e com mediana ~0.09, mas dispers√£o elevada e baixa precis√£o.
- EAS e EUR_ADMIX t√™m valores muito baixos (~0.01-0.05), refletindo baixa probabilidade predita, e previs√£o praticamente ausente. 
- EUR exibe maior n√∫mero de outliers acima de 0.2, com mediana perto dos 0.05, indicando que apesar de ser a classe mais frequentemente prevista, existem incertezas em algumas previs√µes. 
- SAS e SAS_ADMIX mostram linhas planas indicando baixa variabilidade e occorr√™ncia esparsa. SAS_ADMIX tem apenas um valor fixo, sugerindo poucos ou um √∫nico exemplo.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## A. Random Forest com SMOTE ---- Cancer

# Verificar consist√™ncia dos dados
common_samples <- intersect(colnames(expr_all), names(f_cancer))
logCPM_sub <- expr_all[, common_samples]
labels <- f_cancer[common_samples]  # Ajustando para usar f_cancer corretamente

# Criar dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  # Genes como colunas, amostras como linhas
data_model$Cancer <- factor(labels)  # Alterando nome para refletir f_cancer

# Garantir que os levels s√£o v√°lidos para SMOTE
levels(data_model$Cancer) <- make.names(levels(data_model$Cancer))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Cancer, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Aplicar SMOTE
# Remover colunas n√£o num√©ricas
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]

# Encontrar o tamanho m√≠nimo da classe
min_class_size <- min(table(trainData$Cancer))

# Ajustar K para evitar erro de SMOTE
K_value <- max(1, min_class_size - 1)  # Garante que K seja pelo menos 1

# Aplicar SMOTE com K ajustado
smote_result_rf <- SMOTE(trainData_numeric, trainData$Cancer, K = K_value, dup_size = 2)
smote_data_rf <- smote_result_rf$data

# Ajustar nomes das colunas
colnames(smote_data_rf)[ncol(smote_data_rf)] <- "Cancer"
smote_data_rf$Cancer <- factor(smote_data_rf$Cancer, levels = levels(trainData$Cancer))

# Remover valores ausentes
smote_data_rf <- na.omit(smote_data_rf)

# Treinar modelo Random Forest
set.seed(123)
fit_rf4 <- train(Cancer ~ ., data = smote_data_rf, method = "rf", 
                trControl = ctrl1,
                tuneGrid = expand.grid(mtry = 2),  # Ajuste do n√∫mero de vari√°veis
                metric = "ROC",
                ntree = 100)  # N√∫mero de √°rvores ajustado

# Avalia√ß√£o no teste
pred_rf <- predict(fit_rf4, testData)
conf_matrix <- confusionMatrix(pred_rf, testData$Cancer)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- Astrocytoma: 44 corretos, 16 classificados como Oligoastrocytoma, 13 como Oligodendroglioma.
- Oligoastrocytoma: 29 corretos, 46 classificados como Astrocytoma, 25 como Oligodendroglioma.
- Oligodendroglioma: 48 corretos, 17 classificados como Oligoastrocytoma, 1 como Astrocytoma.

Astrocytoma e Oligodendroglioma s√£o razoavelmente bem classificados. Oligoastrocytoma tem o pior desempenho, frequentemente confundida com Astrocytoma. A distribui√ß√£o de erros mostra alguma capacidade de distin√ß√£o, mas com sobreposi√ß√£o nas caracter√≠sticas entre as classes.

M√©tricas de Desempenho:

- Accuracy: 0.5063 ‚Üí O modelo classifica corretamente 50.63% dos exemplos, o que pode ser melhorado. 
- Kappa: 0.2694 ‚Üí Indica concord√¢ncia moderada entre previs√µes e valores reais. 
- Mcnemar's Test P-Value: 8.151e-06 ‚Üí P-valor baixo, indicando diferen√ßas estatisticamente significativas entre algumas classes.

Especificidade: O modelo consegue distinguir melhor Oligodendroglioma das demais classes.
- Astrocytoma: 0.8041
- Oligoastrocytoma: 0.5989
- Oligodendroglioma: 0.8824

Balanced Accuracy: Astrocytoma e Oligodendroglioma t√™m desempenho razo√°vel, sendo que Oligoastrocytoma tem a pior acur√°cia balanceada, indicando que o modelo tem dificuldades em prever essa classe corretamente.
- Astrocytoma: 0.6438
- Oligoastrocytoma: 0.5333
- Oligodendroglioma: 0.7202

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Tabela confusion matrix 
conf_table <- conf_matrix$table

# Inicializa data frame para armazenar metricas
class_metrics <- data.frame(Class = levels(testData$Cancer),
                            Precision = numeric(length(levels(testData$Cancer))),
                            Recall = numeric(length(levels(testData$Cancer))),
                            F1_Score = numeric(length(levels(testData$Cancer))))

# Ciclo sobre cada classe para calcular precis√£o, sensibilidade e F1 score
for (class in levels(testData$Cancer)) {
  # Verdadeiros Positivos (VP): Previs√µes corretas da classe
  TP <- conf_table[class, class]
  
  # Falsos Positivos (FP): Previs√µes da classe, mas pertencem a outra
  FP <- sum(conf_table[, class]) - TP
  
  # Falsos Negativos (FN): Pertencem √† classe, mas foram previstos como outra
  FN <- sum(conf_table[class, ]) - TP
  
  # Precis√£o: VP / (VP + FP)
  precision <- ifelse((TP + FP) == 0, NA, TP / (TP + FP))
  
  # Sensibilidade (Recall): VP / (VP + FN)
  recall <- ifelse((TP + FN) == 0, NA, TP / (TP + FN))
  
  # F1 Score: 2 * (Precis√£o * Sensibilidade) / (Precis√£o + Sensibilidade)
  f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA, 2 * (precision * recall) / (precision + recall))
  
  # Guardar os resultados
  class_metrics[class_metrics$Class == class, ] <- c(class, precision, recall, f1)
}


# Converter colunas num√©ricas
class_metrics[, 2:4] <- lapply(class_metrics[, 2:4], as.numeric)

# Round
class_metrics_rounded <- class_metrics
class_metrics_rounded[, 2:4] <- round(class_metrics_rounded[, 2:4], 3)

# Tabela
knitr::kable(class_metrics_rounded, caption = "Per-Class Performance Metrics (Precision, Recall, F1 Score)")
```

Recall: 

- Astrocytoma: 0.4835
- Oligoastrocytoma: 0.4677
- Oligodendroglioma: 0.5581

Precision:

- Astrocytoma: 0.6027
- Oligoastrocytoma: 0.29
- Oligodendroglioma: 0.7273

F1 Score: 

- Astrocytoma: 0.5366
- Oligoastrocytoma: 0.358
- Oligodendroglioma: 0.6316


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Calcular AUC e Curva ROC
roc_curve <- roc(testData$Cancer, as.numeric(pred_rf))
auc_score <- auc(roc_curve)
print(paste("AUC Score:", auc_score))

plot(roc_curve, col = palette_3, main = "ROC Curve for Random Forest (com SMOTE)")
```

Forma da Curva:

- A curva segue um padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes em diferentes limiares de classifica√ß√£o.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5).Como a curva do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

- AUC Score: 0.6794 ‚Üí Tem uma boa capacidade de distinguir entre as classes, especialmente Astrocytoma e Oligodendroglioma. No entanto, o modelo n√£o √© considerado √∫til (s√≥ acima de 0.75).

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Ver import√¢ncia dos genes
importance <- varImp(fit_rf4)

# Extra√ß√£o variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 126432 com um peso de 100 e Gene 5906 com peso 97.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 80), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo.
- O modelo pode estar dependente de poucos genes-chave, enquanto outros t√™m impacto reduzido. Isso pode indicar que algumas caracter√≠sticas podem ser removidas sem afetar o desempenho.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Visualizar distribui√ß√£o de probabilidades
prob_rf <- predict(fit_rf4, testData, type = "prob")
boxplot(prob_rf[,1] ~ testData$Cancer, col = palette_3, 
        main = "Class Probability Distribution", ylab = "Predicted Probability")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Astrocytoma:

- Mediana alta, indicando previs√µes confiantes e sem outliers, pelo que o modelo √© est√°vel e com alta confian√ßa para esta classe.

Oligoastrocytoma

- Mediana mais baixa do que Astrocytoma e sem outliers, pelo que h√° menor confian√ßa m√©dia nas previs√µes para esta classe.  

Oligodendroglioma

- Mediana mais baixa do que Oligoastrocytoma com baixa variablidade e outlier acima do 0.5. O modelo √© de baixa confi√¢ncia ao prever esta classe. 


### **11.2 Support Vector Machine**
```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

## B. Support Vector Machine com SMOTE ---- SURVIVAL

# Preparar dados
common_samples <- intersect(colnames(expr_all), names(f_survival))
logCPM_sub <- expr_all[, common_samples]
labels <- f_survival[common_samples]

# Criar data frame com amostras como linhas e genes como colunas
data_model <- as.data.frame(t(logCPM_sub))
data_model$SurvivalStatus <- factor(labels)
levels(data_model$SurvivalStatus) <- make.names(levels(data_model$SurvivalStatus))  # tornar nomes v√°lidos

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$SurvivalStatus, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Aplicar SMOTE
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
smote_result <- SMOTE(trainData_numeric, target = trainData$SurvivalStatus, K = 3, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "SurvivalStatus"
smote_data$SurvivalStatus <- factor(smote_data$SurvivalStatus,
                                    levels = levels(trainData$SurvivalStatus))

# Treinar modelo SVM
set.seed(123)
fit_svm1 <- train(SurvivalStatus ~ ., data = smote_data, method = "svmRadial",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  tuneLength=5,
                  metric = "ROC")

# Previs√µes no conjunto de teste
# Garantir que os n√≠veis s√£o iguais
testData$SurvivalStatus <- factor(testData$SurvivalStatus,
                                  levels = levels(fit_svm1$trainingData$.outcome))
pred_class <- predict(fit_svm1, testData)
pred_class <- factor(pred_class, levels = levels(testData$SurvivalStatus))

# Matriz de confus√£o
confusion <- confusionMatrix(pred_class, testData$SurvivalStatus)
pander::pander(confusion, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- 177 previs√µes corretas para "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 12 previs√µes corretas para "X1.DEAD.WITH.TUMOR".
- 8 erros ao classificar "X1.DEAD.WITH.TUMOR" como "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 43 erros ao classificar "XO.ALIVE.OR.DEAD.TUMOR.FREE" como "X1.DEAD.WITH.TUMOR"

Modelo tem boa capacidade de prever a classe "XO.ALIVE.OR.DEAD.TUMOR.FREE", mas mostra dificuldades consider√°veis em identificar corretamente "X1.DEAD.WITH.TUMOR".

M√©tricas de Desempenho:

- Accuracy: 0.7875 ‚Üí Classifica corretamente na maioria dos casos.
- Kappa: 0.2253 ‚Üí Indica um acordo fraco a moderado entre as previs√µes e os valores reais.
- Especificidade: 0.2182 ‚Üí O modelo tem dificultade em acertar os casos negativos.
- Balanced Accuracy: 0.5875 ‚Üí O modelo √© melhor do que o aleat√≥rio, mas ainda pode ser melhorado.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Precision, Recall, F1
positive_class <- "X0.ALIVE.OR.DEAD.TUMOR.FREE"
precision <- posPredValue(pred_class, testData$SurvivalStatus, positive = positive_class)
recall <- sensitivity(pred_class, testData$SurvivalStatus, positive = positive_class)
f1 <- 2 * (precision * recall) / (precision + recall)

cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", round(f1, 3), "\n")
```

- Recall: 0.9568 ‚Üí Identifica 95.68% dos casos positivos corretamente.
- Precis√£o: 0.8045 ‚Üí Quando prev√™ "XO.ALIVE.OR.DEAD.TUMOR.FREE", est√° correto 80.45% das vezes.
- F1 Score: 0.8741 ‚Üí Indica um bom equil√≠brio entre precis√£o e recall, mas reflete sobretudo a classe dominante.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Prever probabilidades
pred_prob <- predict(fit_svm1, testData, type = "prob")

# AUC
correct_col <- grep("ALIVE.OR.DEAD.TUMOR.FREE", colnames(pred_prob), value = TRUE)
roc_curve <- roc(response = testData$SurvivalStatus, predictor = pred_prob[[correct_col]])
auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Curva ROC
plot(roc_curve, col = palette_3, main = "ROC Curve for SVM (com SMOTE)")
```

Forma da Curva:

- A curva ROC est√° num padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes em diferentes limiares de classifica√ß√£o.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5).
- Como a curva ROC do modelo est√° bem acima dessa linha, isso confirma que o modelo tem valor preditivo real.

AUC Score:
- AUC: 0.7808 ‚Üí O modelo tem capacidade razo√°vel de distinguir entre as classes, mas n√£o √© perfeito (abaixo de 0.8).

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Variavel importance
importance <- varImp(fit_svm1, scale = FALSE)

# importance em data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)

importance_df$Overall <- rowMeans(importance_df[, c("X0.ALIVE.OR.DEAD.TUMOR.FREE", "X1.DEAD.WITH.TUMOR")])

# Sort por importance
importance_df <- importance_df[order(-importance_df$Overall), ]

# Seleciona top 20 
top_20 <- head(importance_df, 20)

# tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

# plot
plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 358 com um peso de 0.07793. Este gene tem um impacto significativo na classifica√ß√£o do modelo.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.07), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Boxplot da distribui√ß√£o de probabilidades
df_plot <- data.frame(Prob = pred_prob[[correct_col]], Status = testData$SurvivalStatus)
boxplot(Prob ~ Status, data = df_plot,
        col = palette_3,
        main = "Class Probability Distribution", ylab = "Predicted Probability")


```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe "X0.ALIVE.OR.DEAD.TUMOR.FREE" (vermelho):

- A maioria das previs√µes tem probabilidades pr√≥ximas de 1, indicando alta confian√ßa do modelo nesta classe.
- Existem alguns outliers com probabilidades mais baixas (~0.9), sugerindo casos com menor certeza, possivelmente mais dif√≠ceis de classificar corretamente.

Classe "X1.DEAD.WITH.TUMOR" (azul):

- A distribui√ß√£o √© mais dispersa, com valores variando de 0.5 a 0.9.
- A mediana est√° pr√≥xima de 0.8, indicando que o modelo n√£o tem tanta certeza ao prever esta classe. Pode sugerir dificuldade na separa√ß√£o entre as classes, levando a previs√µes menos confi√°veis.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

## B. Support Vector Machine com SMOTE ---- SEX

# Preparar dados
common_samples <- intersect(colnames(expr_all), names(f_sex))
logCPM_sub <- expr_all[, common_samples]
labels <- f_sex[common_samples]

# Criar data frame com amostras como linhas e genes como colunas
data_model <- as.data.frame(t(logCPM_sub))
data_model$Sex <- factor(labels)

# Garantir que os levels s√£o v√°lidos para uso com class probabilities
levels(data_model$Sex) <- make.names(levels(data_model$Sex))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Sex, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Corrigir aplica√ß√£o do SMOTE
# Remover colunas n√£o num√©ricas
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]  

# Encontrar o tamanho m√≠nimo da classe
min_class_size <- min(table(trainData$Sex))

# Ajustar K para evitar erro de SMOTE
K_value <- max(1, min_class_size - 1)  

# Aplicar SMOTE corretamente (usando factor num√©rico)
smote_result <- SMOTE(trainData_numeric, target = trainData$Sex, K = K_value, dup_size = 2)
smote_data <- smote_result$data

# Ajustar nomes das colunas
colnames(smote_data)[ncol(smote_data)] <- "Sex"
smote_data$Sex <- factor(smote_data$Sex, levels = levels(trainData$Sex))

# Remover valores ausentes
smote_data <- na.omit(smote_data)

# Treinar modelo SVM com valida√ß√£o cruzada e m√©trica ROC
set.seed(123)
fit_svm2 <- train(Sex ~ ., data = smote_data, method = "svmRadial",
                 trControl = ctrl,
                 preProcess = c("center", "scale"),
                 tuneLength=5,
                 metric = "ROC")

# Definir a classe positiva para avalia√ß√£o
positive_class <- "Female"

# Previs√£o do modelo no conjunto de teste
pred_class <- predict(fit_svm2, testData)

# Criar matriz de confus√£o para avaliar o desempenho do modelo
confusion <- confusionMatrix(pred_class, testData$Sex)
pander::pander(confusion, caption = "Estat√≠sticas da Matriz de Confus√£o (por classe)")

# Garantir que testData$Sex √© um fator
testData$Sex <- factor(testData$Sex)                       

# Garantir que as previs√µes t√™m os mesmos n√≠veis que os dados reais
pred_svm <- factor(pred_class, levels = levels(testData$Sex)) 

```

Matriz de confus√£o:

- 36 previs√µes corretas para "Female" e 118 previs√µes corretas para "Male".
- 16 erros ao classificar "Female" como "Male".
- 70 erros ao classificar "Male" como "Female".

Modelo apresenta bom desempenho na classe "Male", mas desempenho fraco na classe "Female". 
A aplica√ß√£o de SMOTE n√£o foi suficiente para corrigir o desequ√≠librio nem para melhorar de forma significativa a sensibilidade para a classe minorit√°ria.

M√©tricas de Desempenho:

- Accuracy: 0.6417 ‚Üí o modelo acerta aproximadamente dois ter√ßos dos casos.
- Kappa: 0.2326 ‚Üí desempenho ligeiramente melhor do modelo aleat√≥rio.
- Especificidade: 0.8806 ‚Üí o modelo reconhece bem a classe "Male", com poucos falsos positivos.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Calcular Precis√£o, Recall e F1 Score
precision <- posPredValue(pred_svm, testData$Sex, positive = positive_class)
recall <- sensitivity(pred_svm, testData$Sex, positive = positive_class)

# Exibir os valores calculados
cat("Precis√£o:", precision, "\n")
cat("Recall:", recall, "\n")

# Calcular o F1 Score apenas se houver valores v√°lidos de precis√£o e recall
if (!is.na(precision) && !is.na(recall) && (precision + recall) > 0) {
  f1 <- 2 * (precision * recall) / (precision + recall)
  cat("F1 Score:", round(f1, 3), "\n")
} else {
  cat("O F1 Score n√£o pode ser calculado devido √† aus√™ncia de precis√£o ou recall.\n")
}

# Previs√£o das probabilidades para cada classe
pred_prob <- predict(fit_svm2, testData, type = "prob")

# Garantir que testData$Sex tem os mesmos n√≠veis que smote_data$Sex
testData$Sex <- factor(testData$Sex, levels = levels(smote_data$Sex))

# Encontrar dinamicamente a coluna correta de probabilidades
sex_levels <- levels(testData$Sex)
correct_col <- grep(paste(sex_levels, collapse = "|"), colnames(pred_prob), value = TRUE)

# Verificar se a coluna correta foi encontrada
if (length(correct_col) == 0) {
  stop(paste("Erro: Coluna de probabilidade para a classifica√ß√£o de Sex n√£o encontrada. Nomes dispon√≠veis:", 
             paste(colnames(pred_prob), collapse = ", ")))
}

# Garantir que apenas uma coluna √© selecionada
if (length(correct_col) > 1) {
  correct_col <- correct_col[1]  # Selecionar a primeira correspond√™ncia
}

# Garantir que o preditor e a resposta t√™m o mesmo comprimento
if (length(testData$Sex) != nrow(pred_prob)) {
  stop("Erro: Incompatibilidade de tamanhos entre testData$Sex e as probabilidades previstas.")
}

# Converter preditor para num√©rico
numeric_pred <- as.numeric(pred_prob[[correct_col]])  

```

- Precis√£o: 0.6923 ‚Üí Quando o modelo prev√™ "Female", est√° correto 69.23% das vezes.
- Recall: 0.3396 ‚Üí Identifica 33.96% dos casos "Female" corretamente.
- F1 Score: 0.4557 ‚Üí Indica baixo equil√≠brio entre precis√£o e recall para esta classe.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular a curva ROC
roc_curve <- roc(response = testData$Sex, predictor = numeric_pred)

# Calcular a AUC (√Årea sob a curva ROC)
auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Plotar a curva ROC
plot(roc_curve, col = palette_3, main = "Curva ROC para SVM (com SMOTE)")
```

Forma da Curva:

- A curva est√° num padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes com base em m√∫ltiplos limiares de classifica√ß√£o.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva do modelo est√° acima da diagonal, o modelo tem desempenho superior ao acaso.

AUC Score:

- AUC: 0.723 ‚Üí O modelo tem capacidade moderada de distinguir entre as classes "Female" e "Male".

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular a import√¢ncia das vari√°veis (genes)
importance <- varImp(fit_svm2, scale = FALSE)

# Converter import√¢ncia para um data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)

# Criar uma m√©trica geral de import√¢ncia combinando as classes "Female" e "Male"
importance_df$Overall <- rowMeans(importance_df[, c("Female", "Male")])

# Ordenar por import√¢ncia
importance_df <- importance_df[order(-importance_df$Overall), ]

# Selecionar as 20 caracter√≠sticas mais importantes
top_20 <- head(importance_df, 20)

# Exibir tabela com os genes mais importantes
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Genes Mais Importantes")

# Plot da import√¢ncia das caracter√≠sticas
plot(importance, top = 20, main = "Top 20 Caracter√≠sticas Mais Importantes")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 22829 com um peso de 0.0998, o qual domina completamente a decis√£o do modelo.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.08), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Criar um data frame para o boxplot
df_plot <- data.frame(Prob = pred_prob[, correct_col], Status = testData$Sex)

# Gerar o boxplot para visualizar a distribui√ß√£o das probabilidades previstas
boxplot(pred_prob[, correct_col] ~ testData$Sex, 
        col = palette_3, 
        main = "Distribui√ß√£o das Probabilidades por Classe", ylab = "Probabilidade Prevista")


```
Boxplot - Distribui√ß√£o das Probabilidades:

Classe "Female" (vermelho):

- Possui uma mediana perto dos 0.3, indicando previs√µes moderadamente confiantes.
- Dispers√£o alta com o Q3 perto dos 0.6 e o Q1 perto dos 0.1, isto sugere que o modelo tem dificuldade em ser consistente ao prever esta classe.

Classe "Male" (azul):

- Possui uma mediana baixa perto dos 0.05, indicando previs√µes mais consistentes para prever esta classe.
- Poucos outliers acima dos 0.6, sugerindo robustez do modelo.

A sobreposi√ß√£o nas distribui√ß√µes de probabilidade entre as duas classes mostra que o modelo tem dificuldade em separ√°-las com confian√ßa. Isto confirma o desempenho desigual observado nas m√©tricas e matriz de confus√£o, particularmente a fraca performance na classe "Female". 

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# --- B. Support Vector Machine com SMOTE ---- ANCESTRALIDADE

# Preparar dados
clean_data_for_2part <- clini_data_no_na

# Definir vari√°vel resposta
f_ancestralidade <- as.factor(clini_data_no_na$ancestry)
names(f_ancestralidade) <- clini_data_no_na$sample_ID

# Alinhar dados de express√£o com amostras com dados cl√≠nicos
common_samples <- intersect(colnames(expr_all), names(f_ancestralidade))
logCPM_sub <- expr_all[, common_samples]
labels <- f_ancestralidade[common_samples]

# Criar data frame com amostras como linhas e genes como colunas
data_model <- as.data.frame(t(logCPM_sub))
data_model$Ancestralidade <- factor(labels)

# Garantir que os levels s√£o v√°lidos para uso com class probabilities
levels(data_model$Ancestralidade) <- make.names(levels(data_model$Ancestralidade))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Ancestralidade, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# --- FILTRAR CLASSES RARAS (< 5 amostras) ---
min_samples <- 5
table_counts <- table(trainData$Ancestralidade)
keep_levels <- names(table_counts[table_counts >= min_samples])

trainData_filtered <- trainData[trainData$Ancestralidade %in% keep_levels, ]
trainData_filtered$Ancestralidade <- droplevels(trainData_filtered$Ancestralidade)

# Atualizar levels no conjunto de teste para corresponder
testData <- testData[testData$Ancestralidade %in% keep_levels, ]
testData$Ancestralidade <- droplevels(testData$Ancestralidade)

# Preparar dados num√©ricos para SMOTE
trainData_numeric <- trainData_filtered[, sapply(trainData_filtered, is.numeric)]  

# Encontrar novo tamanho m√≠nimo da classe
min_class_size <- min(table(trainData_filtered$Ancestralidade))
K_value <- max(1, min_class_size - 1)

# Aplicar SMOTE
smote_result <- SMOTE(trainData_numeric, target = trainData_filtered$Ancestralidade, K = K_value, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "Ancestralidade"
smote_data$Ancestralidade <- factor(smote_data$Ancestralidade, levels = levels(trainData_filtered$Ancestralidade))

# Remover NAs
smote_data <- na.omit(smote_data)

# Treinar modelo SVM
set.seed(123)
fit_svm3 <- train(Ancestralidade ~ ., data = smote_data, method = "svmRadial",
                 trControl = ctrl1,
                 preProcess = c("center", "scale"),
                 tuneLength=5,
                 metric = "Accuracy")

# Previs√£o do modelo no conjunto de teste
pred_class <- predict(fit_svm3, testData)

# Criar matriz de confus√£o
conf_matrix <- confusionMatrix(pred_class, testData$Ancestralidade)
pander::pander(conf_matrix, caption = "Estat√≠sticas da Matriz de Confus√£o (por classe)")
```

Matriz de Confus√£o:

- 218 previs√µes corretas para "EUR", mas teve dificuldades nas outras classes.
- Confirma que o modelo est√° enviesado para prever EUR corretamente, mas falha nas outras classes

M√©tricas de Desempenho:

- Accuracy: 0.9689 ‚Üí Classifica corretamente na maioria dos casos para a classe dominante.
- AccuracyLower: 0.937 e AccuracyUpper: 0.9874 ‚Üí o intervalo de confian√ßa de accuracy mostra estabilidade na mesma tend√™ncia enviesada
- AccuracyNull: 0.9689 ‚Üí o modelo pode estar apenas a prever a classe dominante.
- Kappa: 0 ‚Üí indica que o modelo n√£o est√° a prever melhor do que um classificador aleat√≥rio.
- Especificidade: 1 ‚Üí como o modelo n√£o identifica corretamente as classes negativas, parece haver confus√£o com a sensibilidade ou precis√£o.
- Balanced Accuracy: 0.5 ‚Üí sugere um desempenho aleat√≥rio quando se consideram todas as classes iguais
- p-value da accuracy (0.5987) indica que n√£o h√° diferen√ßa estat√≠stica significativa entre o modelo e um classificador aleat√≥rio.
- McNemarPValue: 0.02334 ‚Üí poss√≠vel desequil√≠brio nos erros, isto √©, o modelo trata uma classe de forma muito diferente das outras.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular Precis√£o, Recall e F1 Score por classe
precision_vec <- diag(conf_matrix$table) / colSums(conf_matrix$table)
recall_vec <- diag(conf_matrix$table) / rowSums(conf_matrix$table)

# Calcular F1-score para cada classe
f1_vec <- ifelse((precision_vec + recall_vec) > 0,
                 2 * (precision_vec * recall_vec) / (precision_vec + recall_vec),
                 NA)

# Criar um data frame com os valores de F1-score
f1_scores <- data.frame(
  Classe = rownames(conf_matrix$table),
  Precis√£o = round(precision_vec, 3),
  Recall = round(recall_vec, 3),
  F1 = round(f1_vec, 3)
)

cat("F1, Recall e Precis√£o por classe:\n")
knitr::kable(f1_scores, caption = "Precis√£o, Recall e F1 Score por Classe")

# Previs√£o de probabilidades (para AUC e boxplot)
pred_prob <- predict(fit_svm3, testData, type = "prob")

# Garantir que testData$Ancestralidade tem os mesmos n√≠veis que pred_prob
testData$Ancestralidade <- factor(testData$Ancestralidade, levels = colnames(pred_prob))

```

- Precis√£o: NA ‚Üí Prev√™ apenas a classe "EUR" com alta confian√ßa.
- Recall: 0 ‚Üí Identifica bem apenas a classe "EUR".
- F1 Score: NA  ‚Üí Prev√™ apenas a classe "EUR" com alta confian√ßa.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Criar listas para armazenar curvas ROC e valores de AUC
roc_list <- list()
auc_scores <- c()
classes <- colnames(pred_prob)

# Calcular curvas ROC para cada classe (um-contra-todos)
for (class_name in classes) {
  # Criar r√≥tulos bin√°rios: 1 para a classe atual, 0 para as restantes
  binary_response <- factor(ifelse(testData$Ancestralidade == class_name, class_name, paste0("not_", class_name)))
  
  # Calcular curva ROC
  roc_curve <- roc(response = binary_response,
                   predictor = pred_prob[, class_name],
                   levels = c(paste0("not_", class_name), class_name))
  
  # Guardar valores de AUC e curva ROC
  auc_score <- auc(roc_curve)
  auc_scores <- c(auc_scores, auc_score)
  roc_list[[class_name]] <- roc_curve
  
  cat(paste("AUC para", class_name, "vs todos:", round(auc_score, 3), "\n"))
}

# Plot a primeira curva ROC
plot(roc_list[[1]], col = palette_3[1], main = "Curvas ROC Multi-classe para SVM (com SMOTE)")
```

Forma da Curva:

- A curva ROC tem uma forma degraudo e irregular, permanecendo perto da linha diagonal, o que indica baixa capacidade de separa√ß√£o entre classes. 

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva est√° um pouco acima da diagonal, o desempenho √© ligeiramente melhor que o acaso, mas sem ganhos significativos. 

AUC Score:

- AUC: 0.649 ‚Üí o modelo tem um desempenho fraco na sua capacidade discriminativa, mas √© melhor que aleat√≥rio.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular a import√¢ncia das vari√°veis (genes)
importance <- varImp(fit_svm3, scale = FALSE)

# Converter import√¢ncia para um data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)

# Criar uma m√©trica geral de import√¢ncia
importance_df$Overall <- rowMeans(importance_df[, c("AFR", "EUR")])

# Ordenar por import√¢ncia
importance_df <- importance_df[order(-importance_df$Overall), ]

# Selecionar as 20 caracter√≠sticas mais importantes
top_20 <- head(importance_df, 20)

# Exibir tabela com os genes mais importantes
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Genes Mais Importantes")

# Plotar a import√¢ncia das caracter√≠sticas
plot(importance, top = 20, main = "Top 20 Caracter√≠sticas Mais Importantes")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 317749 com um peso de 0.9576 e Gene 10901 com peso 0.9249.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.09), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo. 


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
### Corre√ß√£o do Boxplot da Distribui√ß√£o de Probabilidades
# Encontrar dinamicamente a coluna correta de probabilidades
correct_col1 <- grep(paste(levels(testData$Ancestralidade), collapse = "|"), colnames(pred_prob), value = TRUE)

# Garantir que apenas uma coluna √© selecionada
if (length(correct_col1) > 1) {
    correct_col1 <- correct_col1[1]  # Selecionar a primeira correspond√™ncia
}

# Verificar se a coluna correta foi encontrada
if (!(correct_col1 %in% colnames(pred_prob))) {
    stop("Erro: Coluna de probabilidade para a classifica√ß√£o de Ancestralidade n√£o encontrada.")
}

# Converter preditor para num√©rico
numeric_pred <- as.numeric(pred_prob[[correct_col1]])  

# Criar data frame para o boxplot
df_plot <- data.frame(Prob = numeric_pred, Status = testData$Ancestralidade)

# Gerar o boxplot
boxplot(df_plot$Prob ~ df_plot$Status, 
        col = palette_3, 
        main = "Distribui√ß√£o das Probabilidades por Classe", ylab = "Probabilidade Prevista")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe AFR:

- A mediana da probabilidade predita est√° pr√≥xima de 0.01.
- Existe uma baixa dispers√£o e n√£o h√° outliers, sugerindo que o modelo prev√™ esta classe de forma repetitiva, mas com baixa confian√ßa, indicando a sua incapacidade de discrimina√ß√£o real.

Classe EUR:

- A mediana tamb√©m √© pr√≥xima de 0.01, e possui outliers acima de 0.02, indicando alguns casos onde o modelo atribui maior probabilidade. 
- A presen√ßa de outliers em EUR mostra tend√™ncia a superestimar a classe dominante mesmo que discretamente.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## B. Support Vector Machine com SMOTE ---- CANCER

# Preparar dados
common_samples <- intersect(colnames(expr_all), names(f_cancer))
logCPM_sub <- expr_all[, common_samples]
labels <- f_cancer[common_samples]

# Criar data frame com amostras como linhas e genes como colunas
data_model <- as.data.frame(t(logCPM_sub))
data_model$Cancer <- factor(labels)

# Garantir que os levels s√£o v√°lidos para uso com class probabilities
levels(data_model$Cancer) <- make.names(levels(data_model$Cancer))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Cancer, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Remover colunas n√£o num√©ricas
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]  

# Encontrar o tamanho m√≠nimo da classe
min_class_size <- min(table(trainData$Cancer))

# Ajustar K para evitar erro de SMOTE
K_value <- max(1, min_class_size - 1)  # Garante que K seja pelo menos 1

# Aplicar SMOTE corretamente (usando factor num√©rico)
smote_result <- SMOTE(trainData_numeric, target = trainData$Cancer, K = K_value, dup_size = 2)
smote_data <- smote_result$data

# Ajustar nomes das colunas
colnames(smote_data)[ncol(smote_data)] <- "Cancer"
smote_data$Cancer <- factor(smote_data$Cancer, levels = levels(trainData$Cancer))

# Remover valores ausentes
smote_data <- na.omit(smote_data)

# Treinar modelo SVM com valida√ß√£o cruzada e m√©trica ROC
set.seed(123)
fit_svm4 <- train(Cancer ~ ., data = smote_data, method = "svmRadial",
                 trControl = ctrl1,  # Use multiClassSummary
                 preProcess = c("center", "scale"),
                 tuneLength=5,
                 metric = "Accuracy")  # Use Accuracy for multi-class problems


# Avalia√ß√£o no conjunto de teste
pred_class <- predict(fit_svm4, testData)
confusion <- confusionMatrix(pred_class, testData$Cancer)
pander::pander(confusion, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- Astrocytoma: 69 corretos, 31 classificados como Oligoastrocytoma, 21 como Oligodendroglioma.
- Oligoastrocytoma: 9 corretos, 8 classificados como Astrocytoma, 3 como Oligodendroglioma.
- Oligodendroglioma: 62 corretos, 22 classificados como Oligoastrocytoma, 14 como Astrocytoma.
Astrocytoma e Oligodendroglioma s√£o razoavelmente bem classificados. Oligoastrocytoma tem baixo desempenho, frequentemente confundida com outras. Isto sugere sobreposi√ß√£o nas caracter√≠sticas dos tumores e limites poucos claros entre as classes.

M√©tricas de Desempenho:

- Accuracy: 0.5858 ‚Üí O modelo classifica corretamente 58.58% dos exemplos, o que pode ser melhorado. 
- Kappa: 0.3507 ‚Üí Indica concord√¢ncia moderada entre previs√µes e valores reais. 
- Mcnemar's Test P-Value: 1.842e-06 ‚Üí P-valor baixo, indicando diferen√ßas estatisticamente significativas entre algumas classes.

Especificidade: O modelo consegue distinguir melhor Astrocytoma e Oligodendroglioma.
- Astrocytoma: 0.6486
- Oligoastrocytoma: 0.9379
- Oligodendroglioma: 0.7647

Balanced Accuracy: Astrocytoma e Oligodendroglioma t√™m desempenho razo√°vel, sendo que Oligoastrocytoma tem a pior acur√°cia balanceada, indicando que o modelo tem dificuldades em prever essa classe corretamente.
- Astrocytoma: 0.7034
- Oligoastrocytoma: 0.5415
- Oligodendroglioma: 0.7428

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Extrair tabela confusion matrix 
conf_table <- confusion$table

# Initializa data frame para armazenar m√©tricas
class_metrics <- data.frame(Class = levels(testData$Cancer),
                            Precision = numeric(length(levels(testData$Cancer))),
                            Recall = numeric(length(levels(testData$Cancer))),
                            F1_Score = numeric(length(levels(testData$Cancer))))

# Ciclo sobre cada classe para calcular precis√£o, sensibilidade e F1 score
for (class in levels(testData$Cancer)) {
  # Verdadeiros Positivos (VP): Previs√µes corretas da classe
  TP <- conf_table[class, class]
  
  # Falsos Positivos (FP): Previs√µes da classe, mas pertencem a outra
  FP <- sum(conf_table[, class]) - TP
  
  # Falsos Negativos (FN): Pertencem √† classe, mas foram previstos como outra
  FN <- sum(conf_table[class, ]) - TP
  
  # Precis√£o: VP / (VP + FP)
  precision <- ifelse((TP + FP) == 0, NA, TP / (TP + FP))
  
  # Sensibilidade (Recall): VP / (VP + FN)
  recall <- ifelse((TP + FN) == 0, NA, TP / (TP + FN))
  
  # F1 Score: 2 * (Precis√£o * Sensibilidade) / (Precis√£o + Sensibilidade)
  f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA, 2 * (precision * recall) / (precision + recall))
  
  # Guardar os resultados
  class_metrics[class_metrics$Class == class, ] <- c(class, precision, recall, f1)
}

# Converter colunas num√©ricas
class_metrics[, 2:4] <- lapply(class_metrics[, 2:4], as.numeric)

# Round
class_metrics_rounded <- class_metrics
class_metrics_rounded[, 2:4] <- round(class_metrics_rounded[, 2:4], 3)

# Tabela
knitr::kable(class_metrics_rounded, caption = "Per-Class Performance Metrics (Precision, Recall, F1 Score)")

# Prever probabilidades
pred_prob <- predict(fit_svm4, testData, type = "prob")

# Garantir que testData$Cancer tem os mesmos n√≠veis que smote_data$Cancer
testData$Cancer <- factor(testData$Cancer, levels = levels(smote_data$Cancer))

# Encontrar a coluna correta para probabilidades
cancer_levels <- levels(testData$Cancer)
correct_col <- grep(paste(cancer_levels, collapse = "|"), colnames(pred_prob), value = TRUE)

# Verificar se a coluna correta foi encontrada
if (length(correct_col) == 0) {
  stop(paste("Erro: Coluna de probabilidade para classifica√ß√£o de Cancer n√£o encontrada. Nomes dispon√≠veis:", 
             paste(colnames(pred_prob), collapse = ", ")))
}

# Garantir que apenas uma coluna seja selecionada
if (length(correct_col) > 1) {
  correct_col <- correct_col[1] 
}

# Verificar se os tamanhos das vari√°veis s√£o compat√≠veis
if (length(testData$Cancer) != nrow(pred_prob)) {
  stop("Erro: Diferente n√∫mero de elementos entre testData$Cancer e pred_prob.")
}
```

Recall: 

- Astrocytoma: 0.7582
- Oligoastrocytoma: 0.1452
- Oligodendroglioma: 0.7209

Precision:

- Astrocytoma: 0.5702
- Oligoastrocytoma: 0.45
- Oligodendroglioma: 0.6327

F1 Score: 
- Astrocytoma: 0.6509
- Oligoastrocytoma: 0.2195
- Oligodendroglioma: 0.6739


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Converter preditor para num√©rico
numeric_pred <- as.numeric(pred_prob[[correct_col]])  # Usa [[ ]] para extrair como vetor

# Calcular AUC e Curva ROC
roc_curve <- roc(response = testData$Cancer, predictor = numeric_pred)

auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Plot Curva ROC
plot(roc_curve, col = palette_3, main = "ROC Curve for SVM (com SMOTE)")
```

Forma da Curva:

- A curva segue um padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes em diferentes limiares de classifica√ß√£o.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

- AUC Score: 0.72279 ‚Üí Tem uma capacidade moderada de distinguir entre as classes, especialmente Astrocytoma e Oligodendroglioma.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular a import√¢ncia das vari√°veis no modelo
importance <- varImp(fit_svm4, scale = FALSE)

# Converter a import√¢ncia para um data frame
importance_df <- as.data.frame(importance$importance)

# Adicionar os nomes dos genes como uma coluna separada
importance_df$Gene <- rownames(importance_df)

# Criar uma m√©trica geral de import√¢ncia combinando as classes "Atrocytoma", "Oligoastrocytoma" e "Oligodendroglioma"
importance_df$Overall <- rowMeans(importance_df[, c("Astrocytoma", "Oligoastrocytoma", "Oligodendroglioma")])

# Ordenar os genes por import√¢ncia (do maior para o menor)
importance_df <- importance_df[order(-importance_df$Overall), ]

# Selecionar os 20 genes mais importantes
top_20 <- head(importance_df, 20)

# Exibir tabela com os genes mais importantes
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Genes Mais Importantes")

# Plotar a import√¢ncia das caracter√≠sticas
plot(importance, top = 20, main = "Top 20 Caracter√≠sticas Mais Importantes")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 83931 com um peso de 0.8397 e Gene 55616 com peso 0.8385.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.8), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Boxplot da distribui√ß√£o de probabilidades
df_plot <- data.frame(Prob = pred_prob[[correct_col]], Status = testData$Cancer)

boxplot(pred_prob[[correct_col]] ~ testData$Cancer, 
        col = palette_3, 
        main = "Class Probability Distribution", ylab = "Predicted Probability")

```

Boxplot - Distribui√ß√£o das Probabilidades:

Astrocytoma:

- Mediana alta, indicando previs√µes confiantes e sem outliers, pelo que o modelo √© est√°vel e com alta confian√ßa para esta classe.

Oligoastrocytoma:

- Mediana mais baixa do que Astrocytoma e sem outliers, pelo que h√° menor confian√ßa m√©dia nas previs√µes para esta classe.  

Oligodendroglioma:

- Mediana mais baixa do que Oligoastrocytoma com baixa variablidade e sem outliers. O modelo √© de baixa confi√¢ncia ao prever esta classe. 

### **11.3 XGBoost**
```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## C. XGBoost com SMOTE ---- SURVIVAL

# Preparar dados
clean_data_for_2part <- clini_data_no_na

# Definir vari√°vel resposta
f_survival <- as.factor(clini_data_no_na$surv_status)
names(f_survival) <- clini_data_no_na$sample_ID

# Alinhar dados de express√£o com amostras com dados cl√≠nicos
common_samples <- intersect(colnames(expr_all), names(f_survival))
logCPM_sub <- expr_all[, common_samples]
labels <- f_survival[common_samples]

# Construir dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  # genes como colunas
data_model$SurvivalStatus <- factor(labels)

# Ajustar levels para uso com SMOTE e xgboost
levels(data_model$SurvivalStatus) <- make.names(levels(data_model$SurvivalStatus))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$SurvivalStatus, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# SMOTE
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
smote_result <- SMOTE(trainData_numeric, trainData$SurvivalStatus, K = 3, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "SurvivalStatus"
smote_data$SurvivalStatus <- factor(smote_data$SurvivalStatus, 
                                    levels = levels(trainData$SurvivalStatus))

# Treinar modelo XGBoost
set.seed(123)
capture.output({
  fit_xgb1 <- train(SurvivalStatus ~ ., data = smote_data, method = "xgbTree",
                   trControl = ctrl, 
                   metric ="ROC", 
                   tuneLength=3)
}, file = "NUL")

# Avalia√ß√£o no conjunto de teste
pred_class <- predict(fit_xgb1, testData)
 
conf_matrix <- confusionMatrix(pred_class, testData$SurvivalStatus)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- 161 previs√µes corretas para "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 22 previs√µes corretas para "X1.DEAD.WITH.TUMOR".
- 33 erros ao classificar "X1.DEAD.WITH.TUMOR" como "XO.ALIVE.OR.DEAD.TUMOR.FREE".
- 24 erros ao classificar "XO.ALIVE.OR.DEAD.TUMOR.FREE" como "X1.DEAD.WITH.TUMOR"
- Modelo tem boa capacidade de prever a classe "XO.ALIVE.OR.DEAD.TUMOR.FREE", mas tem dificuldades em prever corretamente "X1.DEAD.WITH.TUMOR".
- Embora treinado com Smote, o modelo pode estar enviesado para prever "XO.ALIVE.OR.DEAD.TUMOR.FREE" com mais frequ√™ncia.

M√©tricas de Desempenho:

- Accuracy: 76.25% ‚Üí Classifica corretamente na maioria dos casos.
- Kappa: 0.2886 ‚Üí Indica um acordo moderado entre as previs√µes e os valores reais.
- Especificidade: 0.4 ‚Üí Tem dificuldade em identificar corretamente os casos negativos.
- Balanced Accuracy: 0.6351 ‚Üí O modelo n√£o est√° completamente equilibrado, pois a especificidade √© baixa.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Previs√£o de probabilidades
pred_prob <- suppressWarnings(predict(fit_xgb1, testData, type = "prob"))
correct_col <- grep("ALIVE.OR.DEAD.TUMOR.FREE", colnames(pred_prob), value = TRUE)

f1_smote <- F1_Score(y_pred = pred_class, y_true = testData$SurvivalStatus, positive = "ALIVE.OR.DEAD.TUMOR.FREE")

# Precision, Recall
positive_class <- "X0.ALIVE.OR.DEAD.TUMOR.FREE"
precision <- posPredValue(pred_class, testData$SurvivalStatus, positive = positive_class)
recall <- sensitivity(pred_class, testData$SurvivalStatus, positive = positive_class)
f1 <- 2 * (precision * recall) / (precision + recall)

cat("Recall:", recall, "\n")
cat("Precision:", precision, "\n")
cat("F1 Score:", round(f1, 3), "\n")
```

- Recall: 0.8703 ‚Üí Identifica 87.03% dos casos positivos corretamente.
- Precis√£o: 0.8299 ‚Üí Quando prev√™ "XO.ALIVE.OR.DEAD.TUMOR.FREE", est√° correto 82.99% das vezes.
- F1 Score: 0.85 ‚Üí Indica um bom equil√≠brio entre precis√£o e recall.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# ROC
roc_curve <- roc(response = testData$SurvivalStatus, predictor = pred_prob[, correct_col])
auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Curva ROC
plot(roc_curve, col = palette_3, main = "ROC Curve for XGBoost (com SMOTE)")
```

Forma da Curva:

- A curva ROC est√° pr√≥xima do canto superior esquerdo, indicando alta sensibilidade e especificidade. Isso significa que o modelo classifica corretamente a maioria dos exemplos, minimizando falsos positivos e falsos negativos.

Compara√ß√£o com um Classificador Aleat√≥rio

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5).
- Como a curva ROC do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

AUC Score

- AUC: 0.7494 ‚Üí O modelo tem capacidade razo√°vel de distinguir entre as classes, mas n√£o √© perfeito (abaixo de 0.8).

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Import√¢ncia das features
importance <- varImp(fit_xgb1, scale = FALSE)

# Extrair variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 90187, com um peso de 0.1019811. Este gene tem um impacto significativo na classifica√ß√£o do modelo.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.03), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Boxplot das probabilidades
boxplot(pred_prob[, correct_col] ~ testData$SurvivalStatus,
        col = palette_3,
        main = "Class Probability Distribution", ylab = "Predicted Probability")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe "X0.ALIVE.OR.DEAD.TUMOR.FREE" (vermelho):

- A maioria das previs√µes tem probabilidades pr√≥ximas de 1, indicando alta confian√ßa do modelo nesta classe.
- Existem alguns outliers com probabilidades mais baixas (~0.2), sugerindo casos amb√≠guos.

Classe "X1.DEAD.WITH.TUMOR" (azul):

- A distribui√ß√£o √© mais espalhada, com valores variando de 0.2 a 0.8.
- A mediana est√° pr√≥xima de 0.5, indicando que o modelo n√£o tem tanta certeza ao prever esta classe. Pode sugerir dificuldade na separa√ß√£o entre as classes, levando a previs√µes menos confi√°veis.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## C. XGBoost com SMOTE - Sex

# Preparar dados
clean_data_for_2part <- clini_data_no_na

# Definir vari√°vel resposta
f_sex <- as.factor(clean_data_for_2part$sex)
names(f_sex) <- clean_data_for_2part$sample_ID

# Alinhar dados de express√£o com amostras com dados cl√≠nicos
common_samples <- intersect(colnames(expr_all), names(f_sex))
logCPM_sub <- expr_all[, common_samples]
labels <- f_sex[common_samples]

# Construir dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  # genes como colunas
data_model$Sex <- factor(labels)

# Ajustar levels para uso com SMOTE e xgboost
levels(data_model$Sex) <- make.names(levels(data_model$Sex))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Sex, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# SMOTE
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
smote_result <- SMOTE(trainData_numeric, trainData$Sex, K = 3, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "Sex"
smote_data$Sex <- factor(smote_data$Sex, levels = levels(trainData$Sex))

# Treinar modelo XGBoost
set.seed(123)
capture.output({
  fit_xgb2 <- train(Sex ~ ., data = smote_data, method = "xgbTree",
                    trControl = ctrl, 
                    metric = "ROC", tuneLength=3)
}, file = "NUL")

# Avalia√ß√£o no conjunto de teste
pred_class <- predict(fit_xgb2, testData)
conf_matrix <- confusionMatrix(pred_class, testData$Sex)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de confus√£o:

- 106 previs√µes corretas para "Female" e 131 previs√µes corretas para "Male".
- Apenas 3 erros ao classificar "Female" como "Male".
- Nenhum erro ao classificar "Male".

Modelo tem alta precis√£o e sensibilidade, especialmente para a classe "Female".

- Treinado com SMOTE (Synthetic Minority Over-sampling Technique), que ajuda a lidar com desbalanceamento de classes.

M√©tricas de Desempenho:

- Accuracy: 98.75% ‚Üí classifica corretamente na maioria dos casos.
- Kappa: 0.9747 ‚Üí Excelente acordo entre as previs√µes e os valores reais.
- Especificidade: 0.9776 ‚Üí Identifica quase todos os exemplos da classe "Male" bem.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Previs√£o de probabilidades
pred_prob <- suppressWarnings(predict(fit_xgb2, testData, type = "prob"))
correct_col <- grep("Female", colnames(pred_prob), value = TRUE)  

# Precision, Recall, F1
positive_class <- "Female"

precision <- posPredValue(pred_class, testData$Sex, positive = positive_class)
recall <- sensitivity(pred_class, testData$Sex, positive = positive_class)
f1 <- 2 * (precision * recall) / (precision + recall)

# Print precision, recall,F1
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", round(f1, 3), "\n")
```

- Precis√£o: 0.9725 ‚Üí Quando o modelo prev√™ "Female", est√° correto 97.25% das vezes.
- Recall: 1 ‚Üí Identifica todos os exemplos da classe "Female" corretamente.
- F1 Score: 0.986 ‚Üí Indica um excelente equil√≠brio entre precis√£o e recall.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Curva ROC e AUC
roc_curve <- roc(response = testData$Sex, predictor = pred_prob[, correct_col])
auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Curva ROC
plot(roc_curve, col = palette_3, main = "ROC Curve for XGBoost (com SMOTE) - Sexo")
```

Forma da Curva:

- A curva est√° muito pr√≥xima do canto superior esquerdo, indicando alta sensibilidade e especificidade, minimizando falsos positivos e falsos negativos.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

AUC Score:

- AUC: 0.9998 ‚Üí Quase perfeita separa√ß√£o entre as classes "Female" e "Male". Distingue muito bem entre as duas classes.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Import√¢ncia das features
importance <- varImp(fit_xgb2, scale = FALSE)

# Extrair variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Gene mais relevante: 22829 com um peso de 0.788.
- Outros genes com menor impacto incluem 8242 (0.0876) e 7403 (0.0295).
- A maioria dos genes tem um impacto relativamente baixo, exceto o primeiro.

Isso sugere que alguns genes t√™m um papel muito forte na classifica√ß√£o, enquanto outros contribuem menos.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Boxplot das probabilidades
boxplot(pred_prob[, correct_col] ~ testData$Sex,
        col = palette_3,
        main = "Distribui√ß√£o das Probabilidades - Sexo", ylab = "Probabilidade Prevista")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe "Female" (vermelho):

- A maioria das previs√µes tem probabilidades pr√≥ximas de 1, indicando alta confian√ßa do modelo.

Classe "Male" (azul):

- A maioria das previs√µes tem probabilidades pr√≥ximas de 0, tamb√©m indicando alta confian√ßa.
- Poucos outliers.

Isso confirma que o modelo classifica com alta confian√ßa, mas pode haver casos amb√≠guos.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## C. XGBoost com SMOTE - Ancestralidade
# Preparar dados
clean_data_for_2part <- clini_data_no_na

# Preparar f_ancestralidade sem NA
f_ancestralidade <- as.factor(clean_data_for_2part$ancestry)
names(f_ancestralidade) <- clean_data_for_2part$sample_ID
f_ancestralidade <- f_ancestralidade[!is.na(f_ancestralidade)]

# Alinhar com dados de express√£o
common_samples <- intersect(colnames(expr_all), names(f_ancestralidade))
logCPM_sub <- expr_all[, common_samples]
labels <- f_ancestralidade[common_samples]

# Criar dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  # genes como colunas
data_model$Ancestralidade <- factor(labels)
data_model <- na.omit(data_model)  # Garantir que n√£o h√° NAs
levels(data_model$Ancestralidade) <- make.names(levels(data_model$Ancestralidade))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$Ancestralidade, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# Remover classes com poucas amostras no treino
min_class_size <- 5
keep_classes <- names(which(table(trainData$Ancestralidade) >= min_class_size))
trainData <- trainData[trainData$Ancestralidade %in% keep_classes, ]
trainData$Ancestralidade <- droplevels(trainData$Ancestralidade)

# Aplicar SMOTE
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
smote_result <- SMOTE(trainData_numeric, trainData$Ancestralidade, K = 3, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "Ancestralidade"
smote_data$Ancestralidade <- factor(smote_data$Ancestralidade, levels = levels(trainData$Ancestralidade))

# Treinar modelo XGBoost
set.seed(123)
capture.output({
  fit_xgb3 <- train(Ancestralidade ~ ., data = smote_data, method = "xgbTree",
                    trControl = ctrl1,
                    metric = "ROC",
                    tuneLength=3)
}, file = "NUL")

# Avalia√ß√£o no conjunto de teste
pred_class <- predict(fit_xgb3, testData)
conf_matrix <- confusionMatrix(pred_class, testData$Ancestralidade)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")
```

Matriz de Confus√£o:

- 218 previs√µes corretas para "EUR", mas teve dificuldades nas outras classes.
- Confirma que o modelo est√° enviesado para prever EUR corretamente, mas falha nas outras classes

M√©tricas de Desempenho:

- Accuracy: 91.21% ‚Üí Classifica corretamente na maioria dos casos.
- AccuracyLower: 0.8688 e AccuracyUpper: 0.9448 ‚Üí accuracy real do modelo pode variar nesse intervalo que representa uma boa estabilidade no desempenho
- AccuracyNull: 0.9121 ‚Üí o modelo pode estar apenas a prever a classe dominante.
- Kappa: 0 ‚Üí indica que o modelo n√£o est√° a prever melhor do que um classificador aleat√≥rio.
- Especificidade: 0.4 ‚Üí Tem dificuldade em identificar corretamente os casos negativos.
- Balanced Accuracy: 0.6351 ‚Üí O modelo n√£o est√° completamente equilibrado, pois a especificidade √© baixa.
- p-value da accuracy (0.5577) indica que n√£o h√° diferen√ßa estat√≠stica significativa entre o modelo e um classificador aleat√≥rio.
- McNemarPValue est√° como NA, o que pode indicar que o teste n√£o foi realizado ou n√£o √© aplic√°vel neste caso.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Previs√£o de probabilidades (para AUC e boxplot)
pred_prob <- suppressWarnings(predict(fit_xgb3, testData, type = "prob"))

# Filtrar apenas as classes "EUR" e "AFR"
testData <- testData[testData$Ancestralidade %in% c("EUR", "AFR"), ]
pred_prob <- predict(fit_xgb3, testData, type = "prob")

# Escolher uma classe como "positiva" arbitr√°ria (por exemplo, a primeira)
positive_class <- colnames(pred_prob)[1]

# Calcular Precision e Recall
precision_vec <- diag(conf_matrix$table) / colSums(conf_matrix$table)
recall_vec <- diag(conf_matrix$table) / rowSums(conf_matrix$table)

# Calcular Macro F1-score manualmente (sem yardstick)
f1_per_class <- function(conf_mat) {
  by_class <- conf_mat$byClass
  if (is.matrix(by_class)) {
    f1 <- 2 * by_class[, "Sensitivity"] * by_class[, "Precision"] /
            (by_class[, "Sensitivity"] + by_class[, "Precision"])
    f1[is.na(f1)] <- 0
    return(mean(f1))
  } else {
    # Only two classes
    f1 <- 2 * by_class["Sensitivity"] * by_class["Precision"] /
            (by_class["Sensitivity"] + by_class["Precision"])
    return(ifelse(is.na(f1), 0, f1))
  }
}

f1_macro <- f1_per_class(conf_matrix)
cat("F1 Score:", round(f1_macro, 3), "\n")
cat("Recall:", round(recall_vec, 3), "\n")
cat("Precision:", round(precision_vec, 3), "\n")
```

- Precis√£o: 1 ‚Üí Prev√™ apenas a classe "EUR" com alta confian√ßa.
- Recall: 0.912 ‚Üí Identifica bem apenas a classe "EUR".
- F1 Score: 0.119  ‚Üí Indica um score muito baixo, o que indica um grande desequil√≠brio entre precis√£o e recall.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
roc_curve <- roc(response = testData$Ancestralidade, 
                 predictor = pred_prob[, positive_class], 
                 levels = c("EUR", "AFR"))

auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Plot ROC curve
plot(roc_curve, col = palette_3, lwd = 2, main = "ROC Curve - EUR vs AFR")

# c√°lculo de AUC para multiclasse
multiclass_auc <- multiclass.roc(response = testData$Ancestralidade,
                                 predictor = as.matrix(pred_prob))
auc_score <- auc(multiclass_auc)
cat("Multiclass AUC Score:", round(auc_score, 3), "\n")


```

Forma da Curva:

- A curva segue um padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes em diferentes limiares de classifica√ß√£o, mas est√° acima da linha diagonal, o que significa que o modelo tem um desempenho melhor do que um classificador aleat√≥rio. 

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5). Como a curva do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

AUC Score:

- AUC: 0.827654 ‚Üí Distingue bem algumas das classes.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Import√¢ncia das features
importance <- varImp(fit_xgb3, scale = FALSE)

# Extra√ß√£o variavel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 317749 com um peso de 0.125560 e Gene 283345 com peso 0.1217968.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.07), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo. 
- O modelo pode estar dependente de poucos genes-chave, enquanto outros t√™m impacto reduzido. Isso pode indicar que algumas caracter√≠sticas podem ser removidas sem afetar o desempenho.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Boxplot das probabilidades para cada classe
positive_class <- colnames(pred_prob)[1]
boxplot(pred_prob[, positive_class] ~ testData$Ancestralidade,
        col = palette_3,
        main = paste("Probabilidade predita - Classe:", positive_class),
        ylab = "Predicted Probability")


```

Boxplot - Distribui√ß√£o das Probabilidades:

Classe AFR:

- A mediana da probabilidade predita est√° pr√≥xima de 0.05.
- O intervalo interquartil (IQR) varia entre aproximadamente 0.02 e 0.1, indicando baixa dispers√£o.
- N√£o h√° outliers, sugerindo que o modelo prev√™ esta classe de forma consistente.

Outras classes

- EUR (Europeia) apresenta v√°rios outliers, com probabilidades chegando a 0.35.
- As classes AFR_ADMIX, AMR, EAS, EUR_ADMIX, SAS e SAS_ADMIX t√™m probabilidades pr√≥ximas de zero, indicando que o modelo raramente prev√™ essas classes como AFR.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
## C. XGBoost com SMOTE - Cancer

# Preparar dados
clean_data_for_2part <- clini_data_no_na

# Definir vari√°vel resposta
f_cancer <- as.factor(clean_data_for_2part$cancer_type)
names(f_cancer) <- clean_data_for_2part$sample_ID

# Alinhar dados de express√£o com amostras com dados cl√≠nicos
common_samples <- intersect(colnames(expr_all), names(f_cancer))
logCPM_sub <- expr_all[, common_samples]
labels <- f_cancer[common_samples]

# Construir dataframe para modelagem
data_model <- as.data.frame(t(logCPM_sub))  # genes como colunas
data_model$TipoTumor <- factor(labels)

# Ajustar levels para uso com SMOTE e xgboost
levels(data_model$TipoTumor) <- make.names(levels(data_model$TipoTumor))

# Dividir treino e teste
set.seed(123)
trainIndex <- createDataPartition(data_model$TipoTumor, p = 0.5, list = FALSE)
trainData <- data_model[trainIndex, ]
testData  <- data_model[-trainIndex, ]

# SMOTE
trainData_numeric <- trainData[, sapply(trainData, is.numeric)]
smote_result <- SMOTE(trainData_numeric, trainData$TipoTumor, K = 3, dup_size = 2)
smote_data <- smote_result$data
colnames(smote_data)[ncol(smote_data)] <- "TipoTumor"
smote_data$TipoTumor <- factor(smote_data$TipoTumor, levels = levels(trainData$TipoTumor))

# Treinar modelo XGBoost
set.seed(123)
capture.output({
  fit_xgb4 <- train(TipoTumor ~ ., data = smote_data, method = "xgbTree",
                    trControl = ctrl1, 
                    metric = "ROC", tuneLength=3)
}, file = "NUL")

# Avalia√ß√£o no conjunto de teste
pred_class <- predict(fit_xgb4, testData)
conf_matrix <- confusionMatrix(pred_class, testData$TipoTumor)
pander::pander(conf_matrix, caption = "Confusion Matrix Statistics (per class)")

```

Matriz de Confus√£o:

- Astrocytoma: 58 corretos, 20 classificados como Oligoastrocytoma, 14 como Oligodendroglioma.
- Oligoastrocytoma: 24 corretos, 29 classificados como Astrocytoma, 18 como Oligodendroglioma.
- Oligodendroglioma: 54 corretos, 18 classificados como Oligoastrocytoma, 4 como Astrocytoma.Astrocytoma e Astrocytoma e Oligodendroglioma t√™m melhor desempenho, com sensibilidade acima de 62%. Oligoastrocytoma tem o pior desempenho, com sensibilidade de apenas 38.71%, indicando que o modelo tem dificuldades em identificar corretamente essa classe.

M√©tricas de Desempenho:

- Accuracy: 56.9% ‚Üí O modelo classifica corretamente 56.9% dos exemplos, o que pode ser melhorado. 
- Kappa: 0.3489 ‚Üí Indica concord√¢ncia moderada entre previs√µes e valores reais. 
- Mcnemar's Test P-Value: 0.06554 ‚Üí P-valor relativamente alto, indicando que o modelo pode estar enviesado para certas classes, sem grande distin√ß√£o entre elas.

Especificidade: O modelo distingue bem as classes, mas ainda h√° erros na previs√£o de Oligoastrocytoma.

- Astrocytoma: 77.03%
- Oligoastrocytoma: 73.45%
- Oligodendroglioma: 85.62%

Balanced Accuracy: Oligoastrocytoma tem a pior acur√°cia balanceada, indicando que o modelo tem dificuldades em prever essa classe corretamente.

- Astrocytoma: 70.38%
- Oligoastrocytoma: 56.08%
- Oligodendroglioma: 74.21%

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Previs√£o de probabilidades
pred_prob <- suppressWarnings(predict(fit_xgb4, testData, type = "prob"))

# Escolher uma classe como "positiva" arbitr√°ria (por exemplo, a primeira)
positive_class <- levels(testData$TipoTumor)[1]
roc_curve <-roc(response = testData$TipoTumor, predictor = pred_prob[, positive_class])
auc_score <- auc(roc_curve)
cat("AUC Score:", auc_score, "\n")

# Curva ROC
plot(roc_curve, col = palette_3, main = "ROC Curve for XGBoost (com SMOTE) - TipoTumor")
```

Forma da Curva:

- A curva segue um padr√£o escalonado, indicando que o modelo est√° a tomar decis√µes em diferentes limiares de classifica√ß√£o.

Compara√ß√£o com um Classificador Aleat√≥rio:

- A linha diagonal representa um classificador aleat√≥rio (AUC = 0.5).
- Como a curva do modelo est√° bem acima dessa linha, isso confirma que o modelo tem um desempenho significativamente melhor do que um classificador aleat√≥rio.

- AUC Score: 0.7648 ‚Üí Tem uma boa capacidade de distinguir entre as classes. Acima de 0.75 indica um modelo √∫til.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Calcular F1-score, Recall e Precision (para a mesma classe positiva)
f1_smote <- F1_Score(y_pred = pred_class, y_true = testData$TipoTumor, positive = positive_class)

precision_vec <- diag(conf_matrix$table) / colSums(conf_matrix$table)
recall_vec <- diag(conf_matrix$table) / rowSums(conf_matrix$table)

cat("F1 Score:", f1_smote, "\n")
cat("Recall:", round(recall_vec, 3), "\n")
cat("Precision:", round(precision_vec, 3), "\n")



```

Recall: O modelo identifica bem Astrocytoma e Oligodendroglioma, mas tem dificuldades com Oligoastrocytoma.

- Astrocytoma: 63.74%
- Oligoastrocytoma: 38.71%
- Oligodendroglioma: 62.79% 

Precision:

- Astrocytoma: 77.55%
- Oligoastrocytoma: 77.38%
- Oligodendroglioma: 80.37% 

- F1 Score: 0.6857 ‚Üí O F1 Score mede o equil√≠brio entre precis√£o e recall. Um valor de 0.6857 indica um desempenho razo√°vel.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Import√¢ncia das features
importance <- varImp(fit_xgb4, scale = FALSE)

# Extrair vari√°vel importance como data frame
importance_df <- as.data.frame(importance$importance)
importance_df$Gene <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$Overall), ]  # Sort by importance

# Sele√ß√£o top 20
top_20 <- head(importance_df, 20)

# Tabela
knitr::kable(top_20[, c("Gene", "Overall")], caption = "Top 20 Most Important Genes")

plot(importance, top = 20, main = "Top 20 Important Features")
```

Import√¢ncia dos Genes:

- Genes mais relevantes: 55616 com um peso de 0.0452976 e Gene 1436 com peso 0.0253459.
- Os primeiros 5 genes t√™m valores relativamente altos (acima de 0.02), sugerindo que s√£o os principais respons√°veis pela decis√£o do modelo.
- O modelo pode estar dependente de poucos genes-chave, enquanto outros t√™m impacto reduzido. Isso pode indicar que algumas caracter√≠sticas podem ser removidas sem afetar o desempenho.


```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}

# Boxplot das probabilidades
boxplot(pred_prob[, positive_class] ~ testData$TipoTumor,
        col = palette_3,
        main = "Distribui√ß√£o das Probabilidades - TipoTumor", ylab = "Probabilidade Prevista")
```

Boxplot - Distribui√ß√£o das Probabilidades:

Astrocytoma:

- Mediana alta, indicando que o modelo prev√™ esta classe com confian√ßa.
- Intervalo interquartil (IQR) relativamente estreito, sugerindo baixa variabilidade nas previs√µes.
- Poucos outliers, indicando que o modelo √© consistente ao prever Astrocytoma.

Oligoastrocytoma:

- Mediana mais baixa, indicando que o modelo tem dificuldades em prever esta classe corretamente.
- Maior dispers√£o, sugerindo incerteza nas previs√µes.
- Outliers presentes, indicando que algumas previs√µes s√£o altamente err√°ticas.

Oligodendroglioma:

- Mediana alta, semelhante √† de Astrocytoma.
- Menos variabilidade do que Oligoastrocytoma, indicando que o modelo prev√™ esta classe com mais confian√ßa.
- Poucos outliers, sugerindo boa estabilidade nas previs√µes.

Interpreta√ß√£o:

- O modelo tem alta confian√ßa ao prever Astrocytoma e Oligodendroglioma, mas incerteza ao prever Oligoastrocytoma.
- A maior variabilidade nas previs√µes de Oligoastrocytoma pode estar impactando negativamente a acur√°cia geral do modelo.

## **12. Compara√ß√£o dos modelos por vari√°vel**
```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Vari√°vel Survival

min_resamples <- min(sapply(list(fit_rf1, fit_svm1, fit_xgb1), function(x) nrow(x$resample)))

fit_rf1$resample <- fit_rf1$resample[order(fit_rf1$resample$Resample), ]
fit_svm1$resample <- fit_svm1$resample[order(fit_svm1$resample$Resample), ]
fit_xgb1$resample <- fit_xgb1$resample[order(fit_xgb1$resample$Resample), ]

# Comparar resultados
results_survival <- resamples(list(RF = fit_rf1, SVM = fit_svm1, XGB = fit_xgb1))

summary_df <- as.data.frame(summary(results_survival)$statistics)
summary_df <- rownames_to_column(summary_df, "Metric_Model")

datatable(summary_df, 
          options = list(pageLength = 10, autoWidth = TRUE), 
          caption = "Summary of Resampling Metrics")

# Compara√ß√£o Visual
bwplot(results_survival,
       col = palette_3,
       main = "Medidas ", ylab = "Model")

```
An√°lise da compara√ß√£o:

Accuracy:

- SVM tem a maior mediana de acur√°cia (0.9429), indicando que, em m√©dia, este √© o modelo mais preciso.

- XGB e RF t√™m medianas semelhantes (0.9143), mas RF tem um m√≠nimo mais baixo (0.8571), sugerindo maior variabilidade.

- SVM e XGB atingem a mesma accuracy m√°xima (0.9857), indicando que ambos podem ter um desempenho bom em alguns casos.

Kappa Score:

- SVM tem a maior mediana de Kappa (0.8861), indicando que ele tem a melhor concord√¢ncia entre previs√µes e valores reais.

- XGB tem um Kappa semelhante ao RF na mediana (0.8291 vs. 0.8280), mas atinge um m√°ximo igual ao SVM (0.8863).

- RF tem um Kappa m√≠nimo mais baixo (0.7143), sugerindo que pode ter mais varia√ß√£o na concord√¢ncia.

```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Vari√°vel Sex

min_resamples <- min(sapply(list(fit_rf2, fit_svm2, fit_xgb2), function(x) nrow(x$resample)))

fit_rf2$resample <- fit_rf2$resample[1:min_resamples, ]
fit_svm2$resample <- fit_svm2$resample[1:min_resamples, ]
fit_xgb2$resample <- fit_xgb2$resample[1:min_resamples, ]

# Comparar resultados
results_sex <- resamples(list(RF = fit_rf2, SVM = fit_svm2, XGB = fit_xgb2))

summary_df_sex <- as.data.frame(summary(results_sex)$statistics)
summary_df_sex <- rownames_to_column(summary_df_sex, "Metric_Model")

datatable(summary_df_sex, 
          options = list(pageLength = 10, autoWidth = TRUE), 
          caption = "Summary of Resampling Metrics (Sex)")

# Compara√ß√£o Visual
bwplot(results_sex,
       col = palette_3,
       main = "Medidas ", ylab = "Model")

```

An√°lise de compara√ß√£o:

Accuracy:

- XGB: Maior acur√°cia entre os tr√™s modelos, com valores pr√≥ximos de 1. Baixa variabilidade, indicando alta estabilidade nas previs√µes. O ponto m√©dio (verde) est√° pr√≥ximo do limite superior, sugerindo alta consist√™ncia.

- SVM: Acur√°cia moderada, em torno de 0.8. Maior variabilidade do que XGB, indicando flutua√ß√µes no desempenho. O ponto m√©dio (azul) est√° abaixo do limite superior, sugerindo alguma inconsist√™ncia.

- RF: Menor acur√°cia entre os tr√™s modelos, em torno de 0.7. Maior variabilidade, indicando instabilidade nas previs√µes. O ponto m√©dio (vermelho) est√° no centro do boxplot, sugerindo desempenho inconsistente.
 

Kappa:

- XGB tem o maior Kappa, com valores pr√≥ximos de 1, indicando alta concord√¢ncia entre previs√µes e valores reais.

- SVM tem um Kappa moderado, com valores em torno de 0.5, sugerindo uma concord√¢ncia razo√°vel, mas inferior ao XGB.

- RF tem o menor Kappa, com valores pr√≥ximos de 0.3, indicando baixa concord√¢ncia entre previs√µes e valores reais.



```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Vari√°vel Ancestralidade

min_resamples <- min(sapply(list(fit_rf3, fit_svm3, fit_xgb3), function(x) nrow(x$resample)))

fit_rf3$resample <- fit_rf3$resample[1:min_resamples, ]
fit_svm3$resample <- fit_svm3$resample[1:min_resamples, ]
fit_xgb3$resample <- fit_xgb3$resample[1:min_resamples, ]

# Comparar resultados
results_ancestralidade <- resamples(list(RF = fit_rf3, SVM = fit_svm3, XGB = fit_xgb3))

summary_df_ancestralidade <- as.data.frame(summary(results_ancestralidade)$statistics)
summary_df_ancestralidade <- rownames_to_column(summary_df_ancestralidade, "Metric_Model")

datatable(summary_df_ancestralidade, 
          options = list(pageLength = 10, autoWidth = TRUE), 
          caption = "Summary of Resampling Metrics (Ancestralidade)")

# Compara√ß√£o Visual
bwplot(results_ancestralidade,
       col = palette_3,
       main = "Medidas ", ylab = "Model")


```
Compara√ß√£o Geral dos Modelos:

- XGB (XGBoost): Melhor desempenho na maioria das m√©tricas, especialmente AUC, Balanced Accuracy e F1 Score. Menor variabilidade, indicando maior estabilidade nas previs√µes. Alta precis√£o e recall, sugerindo boa separa√ß√£o entre classes.

- SVM (Support Vector Machine): Desempenho intermedi√°rio, com boa precis√£o e recall, mas maior variabilidade. Pode ser menos est√°vel do que XGB, mas ainda apresenta bons resultados. Kappa e Balanced Accuracy s√£o razo√°veis, indicando concord√¢ncia moderada.

- RF (Random Forest): Menor desempenho em v√°rias m√©tricas, especialmente Kappa e logLoss. Maior variabilidade, sugerindo instabilidade nas previs√µes. Pode ser √∫til para interpreta√ß√£o, mas n√£o √© o melhor modelo em termos de precis√£o.

An√°lise das M√©tricas:

- AUC e Balanced Accuracy: XGB tem os melhores valores, indicando excelente separa√ß√£o entre classes. SVM tem desempenho razo√°vel, mas com maior variabilidade. RF tem os piores valores, sugerindo dificuldade na separa√ß√£o das classes.

- F1 Score e Recall: XGB tem o melhor F1 Score, indicando bom equil√≠brio entre precis√£o e recall. SVM tem recall alto, mas pode ter menor precis√£o. RF tem menor F1 Score, sugerindo baixa concord√¢ncia entre previs√µes e valores reais.

- Kappa e logLoss: XGB tem o melhor Kappa, indicando alta concord√¢ncia entre previs√µes e valores reais. SVM tem um Kappa razo√°vel, mas com maior variabilidade. RF tem o menor Kappa e maior logLoss, sugerindo baixa confiabilidade.



```{r message=FALSE, warning=FALSE, fig.width=12, fig.height=6, results='asis'}
# Vari√°vel Cancer

min_resamples <- min(sapply(list(fit_rf4, fit_svm4, fit_xgb4), function(x) nrow(x$resample)))

fit_rf4$resample <- fit_rf4$resample[1:min_resamples, ]
fit_svm4$resample <- fit_svm4$resample[1:min_resamples, ]
fit_xgb4$resample <- fit_xgb4$resample[1:min_resamples, ]

# Comparar resultados
results_cancer <- resamples(list(RF = fit_rf4, SVM = fit_svm4, XGB = fit_xgb4))

summary_df_cancer <- as.data.frame(summary(results_cancer)$statistics)
summary_df_cancer <- rownames_to_column(summary_df_cancer, "Metric_Model")

datatable(summary_df_cancer, 
          options = list(pageLength = 10, autoWidth = TRUE), 
          caption = "Summary of Resampling Metrics (Cancer)")

# Compara√ß√£o Visual
bwplot(results_cancer,
       col = palette_3,
       main = "Medidas ", ylab = "Model")


```
Compara√ß√£o Geral dos Modelos:

- XGB (XGBoost): Melhor desempenho na maioria das m√©tricas, especialmente AUC, Balanced Accuracy e F1 Score. Menor variabilidade, indicando maior estabilidade nas previs√µes. Alta precis√£o e recall, sugerindo boa separa√ß√£o entre classes.

- SVM (Support Vector Machine): Desempenho intermedi√°rio, com boa precis√£o e recall, mas maior variabilidade. Pode ser menos est√°vel do que XGB, mas ainda apresenta bons resultados Kappa e Balanced Accuracy s√£o razo√°veis, indicando concord√¢ncia moderada.

- RF (Random Forest): Menor desempenho em v√°rias m√©tricas, especialmente Kappa e logLoss. Maior variabilidade, sugerindo instabilidade nas previs√µes. Pode ser √∫til para interpreta√ß√£o, mas n√£o √© o melhor modelo em termos de precis√£o.

An√°lise das M√©tricas:

- AUC e Balanced Accuracy: XGB tem os melhores valores, indicando excelente separa√ß√£o entre classes. SVM tem desempenho razo√°vel, mas com maior variabilidade. RF tem os piores valores, sugerindo dificuldade na separa√ß√£o das classes.

- F1 Score e Recall: XGB tem o melhor F1 Score, indicando bom equil√≠brio entre precis√£o e recall. SVM tem recall alto, mas pode ter menor precis√£o. RF tem menor F1 Score, sugerindo baixa concord√¢ncia entre previs√µes e valores reais.

- Kappa e logLoss: XGB tem o melhor Kappa, indicando alta concord√¢ncia entre previs√µes e valores reais. SVM tem um Kappa razo√°vel, mas com maior variabilidade. RF tem o menor Kappa e maior logLoss, sugerindo baixa confiabilidade.